{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c1456",
   "metadata": {},
   "source": [
    " @2026-2-2\n",
    "\n",
    "+ 调节Fiete,2009的参数，改变bump的数量\n",
    "+ 加入海马模块到grid中\n",
    "+ phase detection\n",
    "+ 多模式学习\n",
    "+ 吸引子测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.stats import poisson\n",
    "from datetime import datetime\n",
    "from matplotlib import cm\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e951dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "visualization_dir = os.path.join(cur_dir, \"visualization\")\n",
    "os.makedirs(visualization_dir, exist_ok=True)\n",
    "\n",
    "hour_stamp = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "save_dir = os.path.join(visualization_dir, hour_stamp)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving assets to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee654fcc",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "+ Grid cells \n",
    "    + Network Wgg generation\n",
    "+ Place cells\n",
    "    + initialize fiexed random projection from Grid to Place: Wpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664ece0",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32   # grid cell number\n",
    "# Network parameters\n",
    "m = 5  # CV = 1/sqrt(m)\n",
    "tau_s = 30/1000    # synaptic time constant (s)\n",
    "# 偏好位置分布在0-1之间\n",
    "x_prefs = np.arange(1, N+1).reshape(-1, 1) / N  # Inherited location preferences\n",
    "# FeedForward input\n",
    "e_mu = 1.5     # velocity gain\n",
    "beta_0 = 70        # uniform input\n",
    "g_gp = 10.0  # gain for place -> grid projections\n",
    "# Graphing parameters\n",
    "bins = np.linspace(0 + 0.01, 1 - 0.01, 50)\n",
    "\n",
    "alpha = 1000       # weight imbalance parameter\n",
    "alpha_bar = 1.001    # Center Surround weight params\n",
    "gamma = 1.05/100   # Center Surround weight params\n",
    "beta_w = 0.8/100     # Center Surround weight params (renamed to avoid conflict with beta_vel)\n",
    "sigma1 = 1\n",
    "sigma2 = 1\n",
    "# x_range = 32    # 直接控制权重函数的x范围\n",
    "# Relative indices for weight function\n",
    "z = np.arange(-N/2, N/2, 1) # [-32,31)  # x从-N/2 - N/2\n",
    "# z = np.linspace(-x_range, x_range, N)  # 这种方法不好控制中点为0\n",
    "# Weight setup\n",
    "crossSection = alpha * (alpha_bar*np.exp(-gamma * z**2/sigma1**2) - np.exp(-beta_w * z**2/sigma2**2))\n",
    "crossSection_shift = np.roll(crossSection, int(N/2))\n",
    "envelope = np.ones((N, 1)) # periodic topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581da899",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize = (12,5))\n",
    "ax[0].plot(crossSection)\n",
    "ax[0].set_title('before shift')\n",
    "# Circular shift\n",
    "# MATLAB: circshift(crossSection, [0 N/2 - 1])\n",
    "# Shift right by N/2-1 positions (axis=0 for rows, axis=1 for columns)\n",
    "ax[1].plot(crossSection_shift)\n",
    "ax[1].set_title('after shift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b729e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weight matrices\n",
    "# MATLAB: zeros(N, N)\n",
    "W_RR = np.zeros((N, N))\n",
    "W_LL = np.zeros((N, N))\n",
    "W_RL = np.zeros((N, N))\n",
    "W_LR = np.zeros((N, N))\n",
    " # Construct weight matrices\n",
    "for i in range(N):\n",
    "    # MATLAB uses 1-based indexing, Python uses 0-based\n",
    "    # In MATLAB: circshift(crossSection, [0 i - 1])\n",
    "    # In Python: np.roll(crossSection, i - 1)\n",
    "    W_RR[i, :] = np.roll(crossSection_shift, i - 1)  # Right neurons to Right neurons\n",
    "    W_LL[i, :] = np.roll(crossSection_shift, i + 1)  # Left neurons to Left neurons\n",
    "    W_RL[i, :] = np.roll(crossSection_shift, i + 1)  # Left neurons to Right neurons\n",
    "    W_LR[i, :] = np.roll(crossSection_shift, i - 1)  # Right neurons to Left neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99811d3a",
   "metadata": {},
   "source": [
    "### HPC\n",
    "设置海马模块的初始参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d153fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hippocampal (place cell) module parameters\n",
    "Nh = 3200  # number of place cells\n",
    "tau_h = 300 / 1000  # hippocampal time constant (s)\n",
    "theta = 0.2  # activation threshold\n",
    "hebb_lr = 1e-4  # Hebbian learning rate for place->grid synapses\n",
    "epsilon = 1e-9\n",
    "relu = lambda x: np.maximum(x, 0.0)\n",
    "gain_pg = 1.0  # gain for grid -> place projections\n",
    "Iext2 = 0.0  # external input to place cells\n",
    "# Synaptic weights\n",
    "W_pg = np.random.normal(0.0, 1.0, size=(Nh, 2 * N))  # grid -> place\n",
    "# Create sparse connectivity mask for grid -> place projections\n",
    "r_pg = 0.001  # sparsity ratio: retain 10% of connections\n",
    "mask_pg = np.random.rand(Nh, 2 * N) < r_pg\n",
    "W_pg = W_pg * mask_pg\n",
    "\n",
    "# 初始从p->g的投射为0\n",
    "Wgp_L = np.zeros((N, Nh))  # place -> left grid\n",
    "Wgp_R = np.zeros((N, Nh))  # place -> right grid\n",
    "p_prev = np.zeros((Nh, 1))  # initial place-cell activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43396c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(W_pg)\n",
    "# plt.colorbar()\n",
    "# plt.xlabel('Grid Cells')\n",
    "# plt.ylabel('Place Cells')   \n",
    "# plt.title('Initial Grid to Place Cell Weights r={}'.format(r_pg)) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8fe35",
   "metadata": {},
   "source": [
    "### 1. Initializing: Grid only Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10fa20",
   "metadata": {},
   "source": [
    "生成位置轨迹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal parameters\n",
    "T = 10            # length of integration time blocks (s)\n",
    "dt = 1/2000        # step size of numerical integration (s)\n",
    "\n",
    "# Trajectory Data (Sinusoidal)\n",
    "# MATLAB: dt:dt:T creates a range from dt to T with step dt\n",
    "time_steps = np.arange(dt, T + dt, dt)\n",
    "x = (np.sin(time_steps * 2 * np.pi / 10) + 1) / 2  # generate sine wave\n",
    "\n",
    "# x = np.hstack([1/1000*np.arange(1000), np.zeros(len(time_steps)-1000)])  # flat trajectory\n",
    "# Calculate velocity\n",
    "v = np.zeros_like(x)\n",
    "v[1:] = (x[1:] - x[:-1]) / dt  # more efficient than loop\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.figure()\n",
    "# plt.plot(x)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214a926",
   "metadata": {},
   "source": [
    "## Phase Separation\n",
    "+ 使用一段轨迹，simulate网络一段时间，收集网络群体活动\n",
    "+ 进行二值化和去噪处理，提取网络的所有相位模式\n",
    "+ 给每个活动状态分配相位编号, 并求出所有相位的平均活动模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebdc260",
   "metadata": {},
   "source": [
    "### 1. Simulate Grid on a Trajectory\n",
    "Collect and Separate Grid States (Phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924ca82",
   "metadata": {},
   "source": [
    "#### Trajectory generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal parameters\n",
    "T = 50            # length of integration time blocks (s)\n",
    "dt = 1/2000        # step size of numerical integration (s)\n",
    "tau_s = 30/1000    # synaptic time constant (s)\n",
    "\n",
    "# Trajectory Data (Sinusoidal)\n",
    "time_steps = np.arange(dt, T + dt, dt)\n",
    "x = (np.sin(time_steps * 2 * np.pi / 10) + 1) / 2  # generate sine wave\n",
    "\n",
    "# x = np.hstack([1/1000*np.arange(1000), np.zeros(len(time_steps)-1000)])  # flat trajectory\n",
    "# Calculate velocity\n",
    "v = np.zeros_like(x)\n",
    "v[1:] = (x[1:] - x[:-1]) / dt  # more efficient than loop\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(x)\n",
    "plt.xlabel( 'Time (s)')\n",
    "plt.ylabel('Position')\n",
    "plt.title('Trajectory over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3dc09",
   "metadata": {},
   "source": [
    "#### Grid simulation  -- withou feedback from Place cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23481a",
   "metadata": {},
   "source": [
    "Note that in V-H, gridbook is created before the Wgp to be learned, so that it assumes grid cells emerge earlier than and indepedent from place cells  \n",
    "Also it assumes that grid patterns preserve with or without feedback from palce cells  \n",
    "**Here we set grid cell to be deterministic neuron to reduce randomness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd165201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiete,2009\n",
    "n_steps = int(T/dt)\n",
    "\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "\n",
    "# calculate spike counts in each time step\n",
    "s_prev = np.zeros((2*N, 1))      # Population activity (256,1)\n",
    "spk = np.zeros((2*N, len(time_steps)))  # Total spiking\n",
    "spk_count = np.zeros((2*N, 1))   # Current spiking\n",
    "# v = np.zeros_like(x)\n",
    "for t in range(1, n_steps):\n",
    "    \n",
    "    # two population of neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0)\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    \n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0)\n",
    "    \n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "\n",
    "    # F_expanded = np.tile(F, (1, m)) * dt\n",
    "    # spk_sub = poisson.rvs(F_expanded)  # Poisson random numbers\n",
    "    # spk_count += np.sum(spk_sub, axis=1, keepdims=True)   # 在m个时间步长中累计发放数量\n",
    "    # # Determine actual spikes for this time step\n",
    "    # spk[:, t] = np.floor(spk_count.flatten() / m) # \n",
    "    # 修改为确定性形式\n",
    "    # spk_count = spk_count % m  # Keep remainder 跨时间步骤累计参与的spike量\n",
    "    spk[:,t:t+1] = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk[:, t:t+1] - s_prev * dt / tau_s\n",
    "    s_prev = s_new\n",
    "    r_all[:,t] = s_new.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae2b7d",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "+ animation\n",
    "+ phase heat plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c645b40",
   "metadata": {},
   "source": [
    "##### Heatplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid neuron activity over time\n",
    "%matplotlib inline\n",
    "left_activity = r_all[:N, :]\n",
    "right_activity = r_all[N:, :]\n",
    "combined_activity = left_activity + right_activity\n",
    "print(combined_activity.shape)\n",
    "im = plt.imshow(np.roll(combined_activity, shift=10, axis=0), aspect='auto', extent=[0, n_steps, 0, 1])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Neuron Position')   \n",
    "plt.colorbar(im, label='Activity Level')\n",
    "plt.title('Population Activity Over Time')\n",
    "plt.plot(1-x, color = 'r', label = 'real position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a25d4e",
   "metadata": {},
   "source": [
    "##### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c65781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of neural activity\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "# Initialize lines\n",
    "line_left, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'r-', alpha=0.7, label='Left Population')\n",
    "line_right, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'b-', alpha=0.7, label='Right Population')\n",
    "line_combined, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'g-', linewidth=2, label='Combined')\n",
    "# Add position indicator\n",
    "pos_line = ax.axvline(0, color='k', linestyle='--', alpha=0.5, label='Current Position')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, np.max(r_all) * 2.1)\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_xlabel('Position Preference')\n",
    "ax.set_ylabel('Neural Activity')\n",
    "# ax.set_title('1D grid Fiete 2009 x = {}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "def update(frame):\n",
    "    t_idx = frame\n",
    "    \n",
    "    # Update activity lines\n",
    "    left_activity = r_all[:N, t_idx]\n",
    "    right_activity = r_all[N:, t_idx]\n",
    "    combined_activity = left_activity + right_activity\n",
    "    \n",
    "    line_left.set_ydata(left_activity)\n",
    "    line_right.set_ydata(right_activity)\n",
    "    line_combined.set_ydata(combined_activity)\n",
    "    # Update title\n",
    "    ax.set_title(f' t = {dt * t_idx:.4f}s x = {round(x[t_idx],2)}')\n",
    "    # Update position line\n",
    "    current_pos = x[t_idx]\n",
    "    pos_line.set_xdata([current_pos, current_pos])\n",
    "    \n",
    "\n",
    "    return line_left, line_right, line_combined, pos_line\n",
    "\n",
    "# Create animation\n",
    "frame_step = 20\n",
    "ani = FuncAnimation(fig, update, frames=range(0, min(n_steps, 20000), frame_step),  # Limit to 1000 frames for performance\n",
    "                    interval=50, blit=True, repeat=True)\n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.event_source.stop()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baae2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving animation...\")\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "# ani.save('neural_sheet_activity'+timestamp+'.mp4', writer='ffmpeg', fps=20, dpi=100)\n",
    "ani.save(os.path.join(save_dir, f'Fiete2009_1D_grid{N}'+timestamp+'.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(\"Animation saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2dcf1",
   "metadata": {},
   "source": [
    "### Phase Readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_activity = r_all[:N, :]\n",
    "right_activity = r_all[N:, :]\n",
    "combined_activity = left_activity + right_activity\n",
    "print(combined_activity.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbe35e",
   "metadata": {},
   "source": [
    "#### Winner-Take-All: Binary Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winner-Take-All (WTA) readout\n",
    "# keep `top_n` most active neurons at each timestep\n",
    "N_neurons, n_steps = combined_activity.shape\n",
    "print(f\"combined_activity shape: {combined_activity.shape}\")\n",
    "\n",
    "top_n = 1  # change this to keep more/fewer winners per timestep\n",
    "wta_activity = np.zeros_like(combined_activity, dtype=int)\n",
    "\n",
    "# indices of the top_n neurons for every timestep (columns)\n",
    "top_idx = np.argpartition(combined_activity, -top_n, axis=0)[-top_n:, :]\n",
    "col_idx = np.broadcast_to(np.arange(n_steps), top_idx.shape)\n",
    "wta_activity[top_idx, col_idx] = 1\n",
    "# print(f\"WTA matrix shape: {wta_activity.shape}, dtype: {wta_activity.dtype}\")\n",
    "\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "# im0 = axes[0].imshow(combined_activity, aspect='auto', cmap='magma',\n",
    "#                      extent=[0, n_steps, 0, 1])\n",
    "# axes[0].set_ylabel('Neuron Preference')\n",
    "# axes[0].set_title('Population Activity (raw)')\n",
    "# plt.colorbar(im0, ax=axes[0], orientation='vertical', label='Activity')\n",
    "\n",
    "# im1 = axes[1].imshow(wta_activity, aspect='auto', cmap=cm.binary,\n",
    "#                      extent=[0, n_steps, 0, 1], vmin=0, vmax=1)\n",
    "# axes[1].set_xlabel('Timestep Index')\n",
    "# axes[1].set_ylabel('Neuron Preference')\n",
    "# axes[1].set_title(f'WTA mask (top {top_n})')\n",
    "# plt.colorbar(im1, ax=axes[1], orientation='vertical', label='Winner')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba34cf",
   "metadata": {},
   "source": [
    "#### Filtering out low-frequent phases--denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f94c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distinct activity patterns over time (based on WTA mask)\n",
    "if 'wta_activity' not in locals():\n",
    "    raise RuntimeError('Run the WTA cell first to create wta_activity.')\n",
    "\n",
    "# 去掉头尾各10000个时间步，避免边缘效应\n",
    "wta_activity_cut = wta_activity[:,10000:-10000]\n",
    "# 沿神经元维度进行打包压缩，每个时间点的神经模式压缩为长度 n_packed\n",
    "packed_patterns = np.packbits(wta_activity_cut.astype(np.uint8), axis=0)\n",
    "# 找出唯一模式及其索引\n",
    "unique_patterns, inverse_idx = np.unique(packed_patterns, axis=1, return_inverse=True)\n",
    "# unique_patterns:(n_packed,34) \n",
    "# inverse_idx: (n_timepoints,)1D向量，每个元素是每个时间点对应模式索引\n",
    "# print(unique_patterns.shape)\n",
    "# 长度为模式数量，元素为模型频数\n",
    "pattern_counts = np.bincount(inverse_idx)\n",
    "total_unique = unique_patterns.shape[1]\n",
    "print(f\"Unique patterns: {total_unique}\")\n",
    "# sort patterns by frequency 对pattern根据频数排序\n",
    "order = np.argsort(pattern_counts)[::-1]\n",
    "pattern_counts = pattern_counts[order]\n",
    "unique_patterns = unique_patterns[:, order]\n",
    "# 这里出现的unique_patterns中很可能包含少数的噪声模式\n",
    "low_idx = np.argwhere(pattern_counts<=5)  # 查看最少频数\n",
    "low_idx.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化unique_patterns\n",
    "unpacked_patterns = [\n",
    "    np.unpackbits(unique_patterns[:, i], count=wta_activity_cut.shape[0])\n",
    "    for i in range(total_unique)\n",
    "]\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 8), sharex=False)\n",
    "uni_matrix = np.stack(unpacked_patterns)\n",
    "uni_sorted = uni_matrix\n",
    "order = np.lexsort((-uni_sorted).T[::-1])  # reverse columns because lexsort works right→left\n",
    "sorted_rows = uni_sorted[order[::-1]]      # flip to get descending\n",
    "\n",
    "sorted_low_idex = np.array([np.argwhere(order==i)[0][0] for i in low_idx]) # 找到原本出现数量少的pattern在排序后的索引位置\n",
    "print(sorted_rows) \n",
    "axes.imshow(sorted_rows, aspect='auto', cmap=cm.binary,\n",
    "                extent=[0, 1, 0, len(unpacked_patterns)])\n",
    "# Highlight low-frequency patterns in red\n",
    "for idx in sorted_low_idex.flatten():\n",
    "    axes.axhline(y=idx, color='red', linewidth=2, alpha=0.7, label = 'Low frequency pattern (<=5)')\n",
    "axes.set_ylabel('Pattern index')\n",
    "axes.legend()\n",
    "axes.set_xlabel('Neuron preference (normalized)')\n",
    "axes.set_title(f'Unique binary patterns (total {len(unpacked_patterns)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化unique_patterns和频数\n",
    "# map back to bit representation for the top few patterns to inspect\n",
    "inspect_k = 40\n",
    "representative_patterns = [\n",
    "    np.unpackbits(unique_patterns[:, i], count=wta_activity_cut.shape[0])\n",
    "    for i in range(min(inspect_k, total_unique))\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "axes[0].bar(np.arange(len(pattern_counts[:50])), pattern_counts[:50])\n",
    "axes[0].set_ylabel('Occurrences')\n",
    "axes[0].set_title(f'Top pattern frequencies unique_patterns={total_unique}')\n",
    "axes[0].set_xlabel('Pattern rank')\n",
    "\n",
    "if representative_patterns:\n",
    "    rep_matrix = np.stack(representative_patterns)\n",
    "    axes[1].imshow(rep_matrix, aspect='auto', cmap=cm.binary,\n",
    "                   extent=[0, 1, 0, len(representative_patterns)])\n",
    "    axes[1].set_ylabel('Pattern index')\n",
    "    axes[1].set_xlabel('Neuron preference (normalized)')\n",
    "    axes[1].set_title(f'Representative binary patterns (top {len(representative_patterns)})')\n",
    "else:\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5be6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out patterns with occurrences less than a threshold (e.g., 5)\n",
    "pattern_counts_filtered = pattern_counts[pattern_counts >= 5]\n",
    "unique_patterns_filtered = unique_patterns[:, pattern_counts >= 5]\n",
    "total_unique_filtered = unique_patterns_filtered.shape[1]\n",
    "\n",
    "inspect_k = 35\n",
    "representative_patterns = [\n",
    "    np.unpackbits(unique_patterns_filtered[:, i], count=wta_activity_cut.shape[0])\n",
    "    for i in range(min(inspect_k, total_unique_filtered))\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 9))\n",
    "axes[0].bar(np.arange(len(pattern_counts_filtered[:50])), pattern_counts_filtered[:50])\n",
    "axes[0].set_ylabel('Occurrences')\n",
    "axes[0].set_title(f'Top pattern frequencies unique_patterns={len(pattern_counts_filtered)}')\n",
    "axes[0].set_xlabel('Pattern rank')\n",
    "\n",
    "if representative_patterns:\n",
    "    rep_matrix = np.stack(representative_patterns)\n",
    "    axes[1].imshow(rep_matrix, aspect='auto', cmap=cm.binary,\n",
    "                   extent=[0, 1, 0, len(representative_patterns)])\n",
    "    axes[1].set_ylabel('Pattern index')\n",
    "    axes[1].set_xlabel('Neuron preference (normalized)')\n",
    "    axes[1].set_title(f'Representative binary patterns (top {len(representative_patterns)})')\n",
    "else:\n",
    "    axes[1].axis('off')\n",
    "\n",
    "A = rep_matrix\n",
    "order = np.lexsort((-A).T[::-1])  # reverse columns because lexsort works right→left\n",
    "sorted_rows = A[order[::-1]]      # flip to get descending\n",
    "print(sorted_rows)\n",
    "axes[2].imshow(sorted_rows, aspect='auto', cmap=cm.binary,   \n",
    "                   extent=[0, 1, 0, len(representative_patterns)]) \n",
    "axes[2].set_ylabel('Pattern index (sorted)')\n",
    "axes[2].set_xlabel('Neuron preference (normalized)')\n",
    "axes[2].set_title(f'Sorted binary patterns (top {len(representative_patterns)})')\n",
    "print(sorted_rows.shape)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23454aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个时间步与sorted_rows中各pattern的相似度\n",
    "similarity_threshold = 0.99  # 相似度阈值\n",
    "n_patterns = sorted_rows.shape[0]\n",
    "n_timesteps = wta_activity.shape[1]\n",
    "\n",
    "# 存储每个时间步最匹配的pattern索引\n",
    "pattern_indices = np.full(n_timesteps, None, dtype=object)\n",
    "max_sims = np.zeros(n_timesteps, dtype=float)\n",
    "# 对每个时间步计算相似度\n",
    "# 与每个pattern比较\n",
    "# Vectorized computation: similarity matrix (n_patterns, n_timesteps)\n",
    "similarity_matrix = np.zeros((n_patterns, n_timesteps))\n",
    "\n",
    "# for p in range(n_patterns):\n",
    "#     pattern = sorted_rows[p]\n",
    "#     # Compute cosine similarity for all timesteps at once\n",
    "#     for t in range(n_timesteps):\n",
    "#         current_activity = wta_activity[:, t]\n",
    "#         similarity_matrix[p, t] = cosine_similarity(current_activity, pattern)\n",
    "# 1. L2 normalize\n",
    "norm = np.linalg.norm(wta_activity, axis=0, keepdims=True)\n",
    "norm[norm==0]=1\n",
    "wta_norm = wta_activity / norm\n",
    "patterns_norm = sorted_rows / np.linalg.norm(sorted_rows, axis=1, keepdims=True)\n",
    "# 2. Cosine similarity matrix (n_patterns, n_timesteps)\n",
    "similarity_matrix = patterns_norm @ wta_norm\n",
    "\n",
    "# Find max similarity and corresponding pattern index for each timestep\n",
    "max_sims = np.max(similarity_matrix, axis=0)\n",
    "pattern_indices = np.argmax(similarity_matrix, axis=0)\n",
    "# Apply threshold filter\n",
    "pattern_indices[max_sims < similarity_threshold] = -1  # Mark below threshold as -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee49066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pattern indices over time\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(pattern_indices)\n",
    "plt.xlabel('Timestep Index')\n",
    "plt.ylabel('Matched Pattern Index')\n",
    "plt.title('Pattern Matching Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e73ef8",
   "metadata": {},
   "source": [
    "#### Calculate Average Patterns of All Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 计算每个pattern的平均活动模式\n",
    "pattern_average_activity = np.zeros((n_patterns, N))\n",
    "pattern_counts_array = np.zeros(n_patterns)\n",
    "\n",
    "for t in range(n_timesteps):\n",
    "    pattern_idx = pattern_indices[t]\n",
    "    if pattern_idx is not None:\n",
    "        pattern_average_activity[pattern_idx] += combined_activity[:, t]\n",
    "        pattern_counts_array[pattern_idx] += 1\n",
    "\n",
    "# 计算平均值（避免除以0）\n",
    "for p in range(n_patterns):\n",
    "    if pattern_counts_array[p] > 0:\n",
    "        pattern_average_activity[p] /= pattern_counts_array[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可视化32个pattern的平均活动模式\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "im = ax.imshow(pattern_average_activity, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "ax.set_xlabel('Neuron Index')\n",
    "ax.set_ylabel('Pattern Index')\n",
    "ax.set_title('Average Activity Pattern for Each Archetype\\n (32 patterns × 64 neurons)')\n",
    "cbar = plt.colorbar(im, ax=ax, label='Mean Activity Level')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印统计信息\n",
    "print(f\"Total timesteps: {n_timesteps}\")\n",
    "print(f\"Timesteps matched to patterns: {np.sum(pattern_counts_array)}\")\n",
    "print(f\"Pattern coverage: {np.sum(pattern_counts_array) / n_timesteps * 100:.2f}%\")\n",
    "print(f\"Pattern occurrence counts: {pattern_counts_array.astype(int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d804bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_average_activity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563d3ba",
   "metadata": {},
   "source": [
    "## Multiple Pattern Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Npatts = pattern_average_activity.shape[0]\n",
    "g_indexes = np.arange(0,Npatts,12)\n",
    "g_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c936d86",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2da4e5",
   "metadata": {},
   "source": [
    "##### 1. Just train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiete,2009 with hippocampal feedback\n",
    "T_trail = 0.1\n",
    "n_steps = int(T_trail/dt)\n",
    "n_runs = 100  # number of trials\n",
    "v = np.zeros(n_runs*n_steps*len(g_indexes))   # 速度输入为0\n",
    "# 初始化为zero\n",
    "Wgp_L = np.zeros((N, Nh))   # reset synapses\n",
    "Wgp_R  =np.zeros((N, Nh))\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_runs*n_steps*len(g_indexes)))\n",
    "r_place = np.zeros((Nh, n_runs*n_steps*len(g_indexes)))\n",
    "p_prev = np.zeros((Nh, 1)) \n",
    "t_all = 0\n",
    "for run in range(n_runs):\n",
    "    for g_idx in g_indexes:\n",
    "        # 每个trial顺序学习Npatts个模式\n",
    "        g = pattern_average_activity[g_idx].reshape(-1,1)  # (N,1)\n",
    "        s_prev = np.vstack([g,g])   # initialize with previous g\n",
    "        spk = 0   # np.zeros((2*N, n_steps))  # Total spiking\n",
    "        for t_s in range(n_steps):\n",
    "        \n",
    "            # Hippocampal (place-cell) dynamics\n",
    "            hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "            phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "            p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "            r_place[:, t_all:t_all + 1] = p_new\n",
    "            \n",
    "            # two population of neurons\n",
    "            # left population\n",
    "            v_L = (1-e_mu * v[t_all])\n",
    "            g_LL = W_LL @ s_prev[:N]\n",
    "            g_LR = W_LR @ s_prev[N:]\n",
    "            G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "            # RIGHT population\n",
    "            v_R = (1 + e_mu * v[t_all])\n",
    "            g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "            g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "            G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "\n",
    "            G = np.vstack([G_L, G_R])\n",
    "                \n",
    "            # Linear transfer function (ReLU) + Poisson Spike\n",
    "            F = G * (G >= 0)  # ReLU activation\n",
    "            spk = F * dt  # 确定性形式\n",
    "            # Update population activity\n",
    "            s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "            r_all[:, t_all:t_all + 1] = s_new\n",
    "\n",
    "            # Hebbian update for place -> grid synapses\n",
    "            hebb_L = np.outer(s_prev[:N].flatten(), p_new.flatten())\n",
    "            hebb_R = np.outer(s_prev[N:].flatten(), p_new.flatten())\n",
    "            # break\n",
    "            Wgp_L += hebb_lr * hebb_L\n",
    "            Wgp_R += hebb_lr * hebb_R\n",
    "            norms_L = np.linalg.norm(Wgp_L, axis=0, keepdims=True)   # axis = 1 对于每一行单独计算，即网格细胞输入归一化 \n",
    "            norms_R = np.linalg.norm(Wgp_R, axis=0, keepdims=True)    # axis = 0 对于每一列单独计算, 位置细胞归一化.每个位置细胞的输出相同\n",
    "            norms_L[norms_L == 0] = 1.0    # 避免除0问题\n",
    "            norms_R[norms_R == 0] = 1.0 \n",
    "            Wgp_L = Wgp_L / norms_L\n",
    "            Wgp_R = Wgp_R / norms_R\n",
    "            s_prev = s_new\n",
    "            p_prev = p_new\n",
    "            t_all += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6980c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5337ab",
   "metadata": {},
   "source": [
    "##### 2. train and save weight history\n",
    "+ large file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ffe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training save weight matrices\n",
    "T_trail = 0.1\n",
    "n_steps = int(T_trail/dt)\n",
    "\n",
    "n_runs = 100  # number of trials\n",
    "# initialize Wgp_L and Wgp_R\n",
    "Wgp_L = np.random.rand(N, Nh) * 0.1\n",
    "# Wgp_L = np.zeros((N, Nh))\n",
    "Wgp_R = np.random.rand(N, Nh) * 0.1\n",
    "# Wgp_R = np.zeros((N, Nh))\n",
    "# normalize weights\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "history_dir = os.path.join(os.getcwd(), \"training_history\")\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "total_steps = n_runs * len(g_indexes) * n_steps\n",
    "save_interval = 100  # 每10个step保存一次\n",
    "total_saved_steps = total_steps // save_interval\n",
    "wgp_L_path = os.path.join(history_dir, f\"Wgp_L_history_{timestamp}.dat\")\n",
    "wgp_R_path = os.path.join(history_dir, f\"Wgp_R_history_{timestamp}.dat\")\n",
    "Wgp_L_history = np.memmap(wgp_L_path, dtype=np.float16, mode='w+', shape=(total_saved_steps, N, Nh))\n",
    "Wgp_R_history = np.memmap(wgp_R_path, dtype=np.float16, mode='w+', shape=(total_saved_steps, N, Nh))\n",
    "\n",
    "v = np.zeros(n_runs*n_steps*len(g_indexes))   # 速度输入为0\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_runs*n_steps*len(g_indexes)))\n",
    "r_place = np.zeros((Nh, n_runs*n_steps*len(g_indexes)))\n",
    "p_prev = np.zeros((Nh, 1)) \n",
    "t_all = 0\n",
    "for run in range(n_runs):\n",
    "    for g_idx in g_indexes:\n",
    "        # 每个trial顺序学习Npatts个模式\n",
    "        g = pattern_average_activity[g_idx].reshape(-1,1)  # (N,1)\n",
    "        s_prev = np.vstack([g,g])   # initialize with previous g\n",
    "        spk = 0   # np.zeros((2*N, n_steps))  # Total spiking\n",
    "        for t_s in range(n_steps):\n",
    "        \n",
    "            # Hippocampal (place-cell) dynamics\n",
    "            hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "            phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "            p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "            r_place[:, t_all:t_all + 1] = p_new\n",
    "            \n",
    "            # two population of neurons\n",
    "            # left population\n",
    "            v_L = (1-e_mu * v[t_all])\n",
    "            g_LL = W_LL @ s_prev[:N]\n",
    "            g_LR = W_LR @ s_prev[N:]\n",
    "            G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "            # RIGHT population\n",
    "            v_R = (1 + e_mu * v[t_all])\n",
    "            g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "            g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "            G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "\n",
    "            G = np.vstack([G_L, G_R])\n",
    "                \n",
    "            # Linear transfer function (ReLU) + Poisson Spike\n",
    "            F = G * (G >= 0)  # ReLU activation\n",
    "            spk = F * dt  # 确定性形式\n",
    "            # Update population activity\n",
    "            s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "            r_all[:, t_all:t_all + 1] = s_new\n",
    "\n",
    "            # Hebbian update for place -> grid synapses\n",
    "            hebb_L = np.outer(s_prev[:N].flatten(), p_new.flatten())\n",
    "            hebb_R = np.outer(s_prev[N:].flatten(), p_new.flatten())\n",
    "            # break\n",
    "            Wgp_L += hebb_lr * hebb_L\n",
    "            Wgp_R += hebb_lr * hebb_R\n",
    "            norms_L = np.linalg.norm(Wgp_L, axis=0, keepdims=True)   # axis = 1 对于每一行单独计算，即网格细胞输入归一化 \n",
    "            norms_R = np.linalg.norm(Wgp_R, axis=0, keepdims=True)    # axis = 0 对于每一列单独计算, 位置细胞归一化.每个位置细胞的输出相同\n",
    "            norms_L[norms_L == 0] = 1.0    # 避免除0问题\n",
    "            norms_R[norms_R == 0] = 1.0 \n",
    "            Wgp_L = Wgp_L / norms_L\n",
    "            Wgp_R = Wgp_R / norms_R\n",
    "\n",
    "            if t_all % save_interval == 0:\n",
    "                idx = t_all // save_interval\n",
    "                if idx < total_saved_steps:\n",
    "                    Wgp_L_history[idx] = Wgp_L.astype(np.float16)\n",
    "                    Wgp_R_history[idx] = Wgp_R.astype(np.float16)\n",
    "\n",
    "            s_prev = s_new\n",
    "            p_prev = p_new\n",
    "            t_all += 1\n",
    "Wgp_L_history.flush()\n",
    "Wgp_R_history.flush()\n",
    "del Wgp_L_history, Wgp_R_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62518185",
   "metadata": {},
   "source": [
    "##### 3. Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_place_grid_feedback(\n",
    "    pattern_average_activity, g_indexes, \n",
    "    N, Nh, dt, tau_s, tau_h,\n",
    "    W_LL, W_LR, W_RR, W_RL, \n",
    "    W_pg, gain_pg, Iext2, theta,\n",
    "    envelope, beta_0, e_mu, g_gp,\n",
    "    hebb_lr, \n",
    "    T_trail=0.1, n_runs=100, \n",
    "    return_activity=False,\n",
    "    initialize_random = False\n",
    "):\n",
    "    \"\"\"\n",
    "    input: pattern_average_activity: ndarray, shape (Npatts, N)\n",
    "    g_indexes: 待训练的列表索引\n",
    "    Returns:\n",
    "    --------\n",
    "    Wgp_L : ndarray, shape (N, Nh)\n",
    "        Learned synaptic weights from place to left grid cells\n",
    "    Wgp_R : ndarray, shape (N, Nh)\n",
    "        Learned synaptic weights from place to right grid cells\n",
    "    r_all : ndarray, shape (2*N, n_steps_total) [optional]\n",
    "        Grid cell activity over all training steps (if return_activity=True)\n",
    "    r_place : ndarray, shape (Nh, n_steps_total) [optional]\n",
    "        Place cell activity over all training steps (if return_activity=True)\n",
    "    \"\"\"\n",
    "    n_steps = int(T_trail / dt)\n",
    "    v = np.zeros(n_runs * n_steps * len(g_indexes))  # velocity input = 0\n",
    "    \n",
    "    \n",
    "    if initialize_random:\n",
    "        # initialize gaussain weights\n",
    "        Wgp_L = np.random.rand(N, Nh) * 0.1\n",
    "        Wgp_R = np.random.rand(N, Nh) * 0.1\n",
    "        norms_L = np.linalg.norm(Wgp_L, axis=0, keepdims=True)\n",
    "        norms_R = np.linalg.norm(Wgp_R, axis=0, keepdims=True)\n",
    "        norms_L[norms_L == 0] = 1.0  # Avoid division by zero\n",
    "        norms_R[norms_R == 0] = 1.0\n",
    "        Wgp_L = Wgp_L / norms_L\n",
    "        Wgp_R = Wgp_R / norms_R\n",
    "    else:\n",
    "        # Initialize synaptic weights\n",
    "        Wgp_L = np.zeros((N, Nh))\n",
    "        Wgp_R = np.zeros((N, Nh))\n",
    "    # Record population spikes\n",
    "    r_all = np.zeros((2*N, n_runs * n_steps * len(g_indexes)))\n",
    "    r_place = np.zeros((Nh, n_runs * n_steps * len(g_indexes)))\n",
    "    p_prev = np.zeros((Nh, 1))\n",
    "    \n",
    "    t_all = 0\n",
    "    for run in range(n_runs):\n",
    "        for g_idx in g_indexes:\n",
    "            # Learn each pattern sequentially per trial\n",
    "            g = pattern_average_activity[g_idx].reshape(-1, 1)  # (N, 1)\n",
    "            s_prev = np.vstack([g, g])  # Initialize with pattern\n",
    "            \n",
    "            for t_s in range(n_steps):\n",
    "                # Hippocampal (place-cell) dynamics\n",
    "                hippo_drive = gain_pg * W_pg @ s_prev + Iext2  # grid -> place input\n",
    "                phi_term = np.maximum(hippo_drive - theta, 0).reshape(-1, 1)\n",
    "                p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "                r_place[:, t_all:t_all + 1] = p_new\n",
    "                \n",
    "                # Two populations of grid neurons\n",
    "                # Left population\n",
    "                v_L = (1 - e_mu * v[t_all])\n",
    "                g_LL = W_LL @ s_prev[:N]\n",
    "                g_LR = W_LR @ s_prev[N:]\n",
    "                G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "                \n",
    "                # Right population\n",
    "                v_R = (1 + e_mu * v[t_all])\n",
    "                g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "                g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "                G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "                \n",
    "                G = np.vstack([G_L, G_R])\n",
    "                \n",
    "                # Linear transfer function (ReLU) + deterministic spike\n",
    "                F = G * (G >= 0)  # ReLU activation\n",
    "                spk = F * dt  # deterministic form\n",
    "                \n",
    "                # Update population activity\n",
    "                s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "                r_all[:, t_all:t_all + 1] = s_new\n",
    "                \n",
    "                # Hebbian update for place -> grid synapses\n",
    "                hebb_L = np.outer(s_prev[:N].flatten(), p_new.flatten())\n",
    "                hebb_R = np.outer(s_prev[N:].flatten(), p_new.flatten())\n",
    "                \n",
    "                Wgp_L += hebb_lr * hebb_L\n",
    "                Wgp_R += hebb_lr * hebb_R\n",
    "                \n",
    "                # Normalize weights\n",
    "                norms_L = np.linalg.norm(Wgp_L, axis=0, keepdims=True)\n",
    "                norms_R = np.linalg.norm(Wgp_R, axis=0, keepdims=True)\n",
    "                norms_L[norms_L == 0] = 1.0  # Avoid division by zero\n",
    "                norms_R[norms_R == 0] = 1.0\n",
    "                Wgp_L = Wgp_L / norms_L\n",
    "                Wgp_R = Wgp_R / norms_R\n",
    "                \n",
    "                s_prev = s_new\n",
    "                p_prev = p_new\n",
    "                t_all += 1\n",
    "    \n",
    "    if return_activity:\n",
    "        return Wgp_L, Wgp_R, r_all, r_place\n",
    "    else:\n",
    "        return Wgp_L, Wgp_R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb6585",
   "metadata": {},
   "source": [
    "##### Visualize training history (if weight history has been saved)\n",
    "+ see if the weight matrix has converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2557e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight matrix evolution\n",
    "%matplotlib widget\n",
    "Wgp_L_hist = np.memmap(wgp_L_path, dtype=np.float32, mode='r', shape=(total_steps, N, Nh))\n",
    "Wgp_R_hist = np.memmap(wgp_R_path, dtype=np.float32, mode='r', shape=(total_steps, N, Nh))\n",
    "vmin = min(Wgp_L_hist.min(), Wgp_R_hist.min())\n",
    "vmax = max(Wgp_L_hist.max(), Wgp_R_hist.max())\n",
    "\n",
    "\n",
    "fig, (ax_L, ax_R) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "im_L = ax_L.imshow(Wgp_L_hist[0], aspect='auto', cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "im_R = ax_R.imshow(Wgp_R_hist[0], aspect='auto', cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "fig.suptitle(f'Evolution of Place{Nh}-to-Grid{N} Weights Over Time')\n",
    "ax_L.set_title('Wgp_L')\n",
    "ax_R.set_title('Wgp_R')\n",
    "for ax in (ax_L, ax_R):\n",
    "    ax.set_xlabel('Place cell index')\n",
    "    ax.set_ylabel('Grid cell index')\n",
    "cbar = fig.colorbar(im_R, ax=[ax_L, ax_R], orientation='vertical', pad=0.02, fraction=0.035)\n",
    "cbar.set_label('Weight strength')\n",
    "\n",
    "def update_wgp(frame_idx):\n",
    "    im_L.set_data(Wgp_L_hist[frame_idx])\n",
    "    im_R.set_data(Wgp_R_hist[frame_idx])\n",
    "    ax_L.set_title(f'Wgp_L (t={frame_idx})')\n",
    "    ax_R.set_title(f'Wgp_R (t={frame_idx})')\n",
    "    return im_L, im_R\n",
    "skip = 300\n",
    "frames = range(0, total_steps, skip)\n",
    "ani = FuncAnimation(fig, update_wgp, frames=frames, interval=80, blit=False, repeat=True)\n",
    "plt.show()\n",
    "# optional saving:\n",
    "# ani.save(os.path.join(history_dir, f'Wgp_history_{timestamp}.gif'), writer='pillow', fps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918846e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.event_source.stop()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb35194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving animation...\")\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "# ani.save('neural_sheet_activity'+timestamp+'.mp4', writer='ffmpeg', fps=20, dpi=100)\n",
    "ani.save(os.path.join(save_dir, f'pg_Mul-1D_Wgp_training'+timestamp+'.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(\"Animation saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb15398",
   "metadata": {},
   "source": [
    "Average Wgp across Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect saved weight histories\n",
    "Wgp_L_hist = np.memmap(wgp_L_path, dtype=np.float32, mode='r', shape=(total_steps, N, Nh))\n",
    "Wgp_R_hist = np.memmap(wgp_R_path, dtype=np.float32, mode='r', shape=(total_steps, N, Nh))\n",
    "Wgp_L_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average weight changes over time\n",
    "delta_wgp_L = np.mean(np.diff(Wgp_L_hist, axis=0), axis=(1,2))\n",
    "delta_wgp_R = np.mean(np.diff(Wgp_R_hist, axis=0), axis=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize average weight changes\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.grid(True, alpha=0.3,color='gray', lw=1, ls='--')\n",
    "plt.plot(delta_wgp_L, label='Delta Wgp_L', color='blue')\n",
    "plt.plot(delta_wgp_R, label='Delta Wgp_R', color='orange')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mean $\\\\Delta$Weight')\n",
    "plt.title('Average Change in Weights Over Time')\n",
    "plt.xlim(1300, delta_wgp_L.shape[0])\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59afaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed-in view of weight changes\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(delta_wgp_L, label='Delta Wgp_L', color='blue')\n",
    "plt.plot(delta_wgp_R, label='Delta Wgp_R', color='orange')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mean Weight Change')\n",
    "plt.title('Average Change in Weights Over Time')\n",
    "plt.xlim(40000, 45000)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301154fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final hippocampal activity pattern\n",
    "%matplotlib inline\n",
    "fig,ax_place = plt.subplots(1,1, figsize = (10,1))\n",
    "initial_place = r_place[:, -1]\n",
    "initial_vmax = max(initial_place.max(), 1e-9)\n",
    "pattern_im = ax_place.imshow(\n",
    "    initial_place[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    extent=[0, Nh, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=initial_vmax,\n",
    ")\n",
    "ax_place.set_yticks([])\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_title('Hippocampal activity (last timestamp)')\n",
    "ax_place.set_xlim(0, Nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864207b0",
   "metadata": {},
   "source": [
    "##### Visualize Averaged Neuronal Activity during Training Process\n",
    "检查活动是否爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15409a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,3), sharex=True)\n",
    "ax[0].plot(r_all.mean(axis=0)[::1000])\n",
    "ax[1].plot(r_place.mean(axis=0)[::1000])\n",
    "ax[0].set_title('Mean Grid Cell Activity Over Time')\n",
    "ax[1].set_title('Mean Place Cell Activity Over Time')\n",
    "ax[1].set_xlabel('Time Step (every 1000 steps)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc7b44",
   "metadata": {},
   "source": [
    "##### Export Trained Weight Matrixes of Wgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = os.path.join(save_dir, 'exports', f'pg_Mul-1D_g{N}_p{Nh}')\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(export_dir, 'Wgp_L_init-randr0001.npy'), Wgp_L)\n",
    "np.save(os.path.join(export_dir, 'Wgp_R_init-randr0001.npy'), Wgp_R)\n",
    "\n",
    "print(f'Wgp_L and Wgp_R saved to {export_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化W_gp\n",
    "fig, (ax_L, ax_R) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Wgp_L\n",
    "im_L = ax_L.imshow(Wgp_L, aspect='auto', cmap='viridis')\n",
    "ax_L.set_xlabel('Place cell index')\n",
    "ax_L.set_ylabel('Grid cell index (Left)')\n",
    "ax_L.set_title(f'Wgp_L (sum={Wgp_L.sum():.2f})')\n",
    "cbar_L = plt.colorbar(im_L, ax=ax_L, orientation='vertical', pad=0.02, fraction=0.046)\n",
    "\n",
    "# Plot Wgp_R\n",
    "im_R = ax_R.imshow(Wgp_R, aspect='auto', cmap='viridis')\n",
    "ax_R.set_xlabel('Place cell index')\n",
    "ax_R.set_ylabel('Grid cell index (Right)')\n",
    "ax_R.set_title(f'Wgp_R (sum={Wgp_R.sum():.2f})')\n",
    "cbar_R = plt.colorbar(im_R, ax=ax_R, orientation='vertical', pad=0.02, fraction=0.046)\n",
    "\n",
    "# Set global colorbar limits\n",
    "vmax_global = max(Wgp_L.max(), Wgp_R.max())\n",
    "vmin_global = min(Wgp_L.min(), Wgp_R.min())\n",
    "im_L.set_clim(vmin_global, vmax_global)\n",
    "im_R.set_clim(vmin_global, vmax_global)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505fe080",
   "metadata": {},
   "source": [
    "##### Visualization of Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f91ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of neural activity with hippocampal feedback\n",
    "%matplotlib widget\n",
    "fig, (ax, ax_place) = plt.subplots(\n",
    "    2, 1, figsize=(10, 7), gridspec_kw={'height_ratios': [4, 0.8], 'hspace': 0.4}\n",
    " )\n",
    "# Initialize grid-cell activity lines\n",
    "line_left, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'r-', alpha=0.7, label='Left Population')\n",
    "line_right, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'b-', alpha=0.7, label='Right Population')\n",
    "line_combined, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'g-', linewidth=2, label='Combined')\n",
    "# Add position indicator\n",
    "# pos_line = ax.axvline(0, color='k', linestyle='--', alpha=0.5, label='Current Position')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, np.max(r_all) * 2.1)\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_xlabel('Position Preference')\n",
    "ax.set_ylabel('Neural Activity')\n",
    "# ax.set_title('1D grid Fiete 2009 x = {}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hippocampal activity heatmap (1D vector displayed as a thin strip)\n",
    "initial_place = r_place[:, 0]\n",
    "initial_vmax = max(initial_place.max(), 1e-9)\n",
    "pattern_im = ax_place.imshow(\n",
    "    initial_place[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    extent=[0, Nh, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=initial_vmax,\n",
    ")\n",
    "ax_place.set_yticks([])\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_title('Hippocampal activity (current timestep)')\n",
    "ax_place.set_xlim(0, Nh)\n",
    "# 创建垂直colorbar并设置位置\n",
    "cbar = fig.colorbar(pattern_im, ax=ax_place, orientation='vertical', \n",
    "                    pad=0.05, fraction=0.05, shrink=0.8)\n",
    "cbar.set_label('FR(norm)', rotation=270, labelpad=15)\n",
    "# 或者使用set_position调整（单位为图形坐标）\n",
    "# cbar.ax.set_position([0.85, 0.15, 0.02, 0.7])  # [左, 下, 宽, 高]\n",
    "def update(frame):\n",
    "    t_idx = frame\n",
    "        \n",
    "\n",
    "    # Update activity lines\n",
    "    left_activity = r_all[:N, t_idx]\n",
    "    right_activity = r_all[N:, t_idx]\n",
    "    combined_activity = left_activity + right_activity\n",
    "\n",
    "    line_left.set_ydata(left_activity)\n",
    "    line_right.set_ydata(right_activity)\n",
    "    line_combined.set_ydata(combined_activity)\n",
    "    # Update title\n",
    "    ax.set_title(f' t = {dt * t_idx:.4f}s x = {round(x[t_idx], 2)}')\n",
    "    # Update position line\n",
    "    # current_pos = x[t_idx]\n",
    "    # pos_line.set_xdata([current_pos, current_pos])\n",
    "    \n",
    "    # Update hippocampal heatmap\n",
    "    place_activity = r_place[:, t_idx]\n",
    "    vmax = max(place_activity.max(), 1e-9)\n",
    "    pattern_im.set_data(place_activity[None, :])\n",
    "    pattern_im.set_clim(0, vmax)\n",
    "    cbar.update_normal(pattern_im)\n",
    "\n",
    "    return line_left, line_right, line_combined, pattern_im\n",
    "\n",
    "# Create animation\n",
    "frame_step = 20\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(0, min(r_all.shape[1], 20000), frame_step),  # Limit to 1000 frames for performance\n",
    "    interval=50,\n",
    "    blit=True,\n",
    "    repeat=True,\n",
    " )\n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbe169",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.event_source.stop()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ani.save('neural_sheet_activity'+timestamp+'.mp4', writer='ffmpeg', fps=20, dpi=100)\n",
    "ani.save(os.path.join(save_dir, f'pg_Mul-1D-training.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(\"Animation saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89331b0c",
   "metadata": {},
   "source": [
    "#### Visualize PI with hpc feedback\n",
    "能否在有海马反馈的条件下进行路径积分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal parameters\n",
    "T = 50            # length of integration time blocks (s)\n",
    "dt = 1/2000        # step size of numerical integration (s)\n",
    "tau_s = 30/1000    # synaptic time constant (s)\n",
    "\n",
    "# Trajectory Data (Sinusoidal)\n",
    "time_steps = np.arange(dt, T + dt, dt)\n",
    "x = (np.sin(time_steps * 2 * np.pi / 10) + 1) / 2  # generate sine wave\n",
    "# x = np.hstack([1/1000*np.arange(1000), np.zeros(len(time_steps)-1000)])  # flat trajectory\n",
    "# x = (time_steps % 50000)\n",
    "# Calculate velocity\n",
    "v = np.zeros_like(x)\n",
    "v[1:] = (x[1:] - x[:-1]) / dt  # more efficient than loop\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(time_steps, x)\n",
    "plt.xlabel( 'Time (s)')\n",
    "plt.ylabel('Position')\n",
    "plt.title('Trajectory over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b27938",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0.3*np.ones_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90894b59",
   "metadata": {},
   "source": [
    "##### With feedback and Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_s = min(T, 10)\n",
    "n_steps = int(T_s/dt)\n",
    "T_feedback_on = 1  # time to turn on feedback (s)\n",
    "\n",
    "stuck_threshold_steps = int(0.5 / dt) \n",
    "stuck_counter = 0\n",
    "last_peak_idx = -1\n",
    "g_ptr = 0  # 用于追踪 g_indexes 中的当前索引\n",
    "g_indexes_ls = g_indexes.tolist()\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "\n",
    "# calculate spike counts in each time step\n",
    "s_prev = np.zeros((2*N, 1))      # initial Population activity (256,1)\n",
    "spk = np.zeros((2*N, n_steps))  # Total spiking\n",
    "p_prev = np.zeros((Nh, 1))      # initial Place cell activity\n",
    "\n",
    "for t in range(1, n_steps):\n",
    "\n",
    "    # Determine current position and reset\n",
    "    current_activity = s_prev[:N] + s_prev[N:]\n",
    "    current_peak_idx = np.argmax(current_activity)\n",
    "    if current_peak_idx == last_peak_idx:\n",
    "        stuck_counter += 1\n",
    "    else:\n",
    "        stuck_counter = 0\n",
    "        last_peak_idx = current_peak_idx\n",
    "        \n",
    "    # 2. 如果检测到卡顿：自动重置为 g_indexes 中的下一个 pattern\n",
    "    if stuck_counter >= stuck_threshold_steps:\n",
    "        g_ptr = (g_ptr + 1) % len(g_indexes_ls)\n",
    "        new_grid = pattern_average_activity[g_indexes_ls[g_ptr]+1].reshape(-1, 1)\n",
    "        s_prev = np.vstack([new_grid, new_grid])\n",
    "        # p_prev = np.zeros((Nh, 1))  # 可选：reset place cell activity\n",
    "        stuck_counter = 0\n",
    "    # Update external input based on current position\n",
    "    # Hippocampal (place-cell) dynamics\n",
    "    hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "    phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "    p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "    r_place[:, t:t + 1] = p_new\n",
    "    \n",
    "    current_g_gp = g_gp if (t * dt >= T_feedback_on) else 0.0\n",
    "\n",
    "    # two population of neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + current_g_gp * Wgp_L @ p_new\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + current_g_gp * Wgp_R @ p_new\n",
    "\n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "    spk = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "    r_all[:, t:t + 1] = s_new\n",
    "    s_prev = s_new\n",
    "    p_prev = p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46258f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of neural activity with hippocampal feedback\n",
    "%matplotlib widget\n",
    "fig, (ax, ax_place) = plt.subplots(\n",
    "    2, 1, figsize=(10, 7), gridspec_kw={'height_ratios': [4, 0.8], 'hspace': 0.4}\n",
    " )\n",
    "# Initialize grid-cell activity lines\n",
    "line_left, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'r-', alpha=0.7, label='Left Population')\n",
    "line_right, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'b-', alpha=0.7, label='Right Population')\n",
    "line_combined, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'g-', linewidth=2, label='Combined')\n",
    "# Add position indicator\n",
    "# pos_line = ax.axvline(0, color='k', linestyle='--', alpha=0.5, label='Current Position')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, np.max(r_all) * 2.1)\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_xlabel('Position Preference')\n",
    "ax.set_ylabel('Neural Activity')\n",
    "# ax.set_title('1D grid Fiete 2009 x = {}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hippocampal activity heatmap (1D vector displayed as a thin strip)\n",
    "initial_place = r_place[:, 0]\n",
    "initial_vmax = max(initial_place.max(), 1e-9)\n",
    "pattern_im = ax_place.imshow(\n",
    "    initial_place[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    extent=[0, Nh, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=initial_vmax,\n",
    ")\n",
    "ax_place.set_yticks([])\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_title('Hippocampal activity (current timestep)')\n",
    "ax_place.set_xlim(0, Nh)\n",
    "# 创建垂直colorbar并设置位置\n",
    "cbar = fig.colorbar(pattern_im, ax=ax_place, orientation='vertical', \n",
    "                    pad=0.05, fraction=0.05, shrink=0.8)\n",
    "cbar.set_label('FR(norm)', rotation=270, labelpad=15)\n",
    "# 或者使用set_position调整（单位为图形坐标）\n",
    "# cbar.ax.set_position([0.85, 0.15, 0.02, 0.7])  # [左, 下, 宽, 高]\n",
    "def update(frame):\n",
    "    t_idx = frame\n",
    "        \n",
    "\n",
    "    # Update activity lines\n",
    "    left_activity = r_all[:N, t_idx]\n",
    "    right_activity = r_all[N:, t_idx]\n",
    "    combined_activity = left_activity + right_activity\n",
    "\n",
    "    line_left.set_ydata(left_activity)\n",
    "    line_right.set_ydata(right_activity)\n",
    "    line_combined.set_ydata(combined_activity)\n",
    "    # Update title\n",
    "    ax.set_title(f' t = {dt * t_idx:.4f}s x = {round(x[t_idx], 2)}')\n",
    "    # Update position line\n",
    "    # current_pos = x[t_idx]\n",
    "    # pos_line.set_xdata([current_pos, current_pos])\n",
    "    \n",
    "    # Update hippocampal heatmap\n",
    "    place_activity = r_place[:, t_idx]\n",
    "    vmax = max(place_activity.max(), 1e-9)\n",
    "    pattern_im.set_data(place_activity[None, :])\n",
    "    pattern_im.set_clim(0, vmax)\n",
    "    cbar.update_normal(pattern_im)\n",
    "\n",
    "    return line_left, line_right, line_combined, pattern_im\n",
    "\n",
    "# Create animation\n",
    "frame_step = 20\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(0, min(r_all.shape[1], 20000), frame_step),  # Limit to 1000 frames for performance\n",
    "    interval=50,\n",
    "    blit=True,\n",
    "    repeat=True,\n",
    " )\n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ani.event_source.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10925c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "ani.save(os.path.join(save_dir, f'pg_PI_feedback_reset_nop_{timestamp}.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(f\"Animation saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3946b4",
   "metadata": {},
   "source": [
    "##### With feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_s = min(T, 10)\n",
    "n_steps = int(T_s/dt)\n",
    "T_feedback_on = 3  # time to turn on feedback (s)\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "\n",
    "# calculate spike counts in each time step\n",
    "s_prev = np.zeros((2*N, 1))      # initial Population activity (256,1)\n",
    "spk = np.zeros((2*N, n_steps))  # Total spiking\n",
    "p_prev = np.zeros((Nh, 1))      # initial Place cell activity\n",
    "\n",
    "for t in range(1, n_steps):\n",
    "    # Hippocampal (place-cell) dynamics\n",
    "    hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "    phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "    p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "    r_place[:, t:t + 1] = p_new\n",
    "    \n",
    "    current_g_gp = g_gp if (t * dt >= T_feedback_on) else 0.0\n",
    "\n",
    "    # two population of neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + current_g_gp * Wgp_L @ p_new\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + current_g_gp * Wgp_R @ p_new\n",
    "\n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "    spk = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "    r_all[:, t:t + 1] = s_new\n",
    "    s_prev = s_new\n",
    "    p_prev = p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18200a81",
   "metadata": {},
   "source": [
    "Visualization of Path integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of neural activity with hippocampal feedback\n",
    "%matplotlib widget\n",
    "fig, (ax, ax_place) = plt.subplots(\n",
    "    2, 1, figsize=(10, 7), gridspec_kw={'height_ratios': [4, 0.8], 'hspace': 0.4}\n",
    " )\n",
    "# Initialize grid-cell activity lines\n",
    "line_left, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'r-', alpha=0.7, label='Left Population')\n",
    "line_right, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'b-', alpha=0.7, label='Right Population')\n",
    "line_combined, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'g-', linewidth=2, label='Combined')\n",
    "# Add position indicator\n",
    "# pos_line = ax.axvline(0, color='k', linestyle='--', alpha=0.5, label='Current Position')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, np.max(r_all) * 2.1)\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_xlabel('Position Preference')\n",
    "ax.set_ylabel('Neural Activity')\n",
    "# ax.set_title('1D grid Fiete 2009 x = {}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hippocampal activity heatmap (1D vector displayed as a thin strip)\n",
    "initial_place = r_place[:, 0]\n",
    "initial_vmax = max(initial_place.max(), 1e-9)\n",
    "pattern_im = ax_place.imshow(\n",
    "    initial_place[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    extent=[0, Nh, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=initial_vmax,\n",
    ")\n",
    "ax_place.set_yticks([])\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_title('Hippocampal activity (current timestep)')\n",
    "ax_place.set_xlim(0, Nh)\n",
    "# 创建垂直colorbar并设置位置\n",
    "cbar = fig.colorbar(pattern_im, ax=ax_place, orientation='vertical', \n",
    "                    pad=0.05, fraction=0.05, shrink=0.8)\n",
    "cbar.set_label('FR(norm)', rotation=270, labelpad=15)\n",
    "# 或者使用set_position调整（单位为图形坐标）\n",
    "# cbar.ax.set_position([0.85, 0.15, 0.02, 0.7])  # [左, 下, 宽, 高]\n",
    "def update(frame):\n",
    "    t_idx = frame\n",
    "        \n",
    "\n",
    "    # Update activity lines\n",
    "    left_activity = r_all[:N, t_idx]\n",
    "    right_activity = r_all[N:, t_idx]\n",
    "    combined_activity = left_activity + right_activity\n",
    "\n",
    "    line_left.set_ydata(left_activity)\n",
    "    line_right.set_ydata(right_activity)\n",
    "    line_combined.set_ydata(combined_activity)\n",
    "    # Update title\n",
    "    ax.set_title(f' t = {dt * t_idx:.4f}s x = {round(x[t_idx], 2)}')\n",
    "    # Update position line\n",
    "    # current_pos = x[t_idx]\n",
    "    # pos_line.set_xdata([current_pos, current_pos])\n",
    "    \n",
    "    # Update hippocampal heatmap\n",
    "    place_activity = r_place[:, t_idx]\n",
    "    vmax = max(place_activity.max(), 1e-9)\n",
    "    pattern_im.set_data(place_activity[None, :])\n",
    "    pattern_im.set_clim(0, vmax)\n",
    "    cbar.update_normal(pattern_im)\n",
    "\n",
    "    return line_left, line_right, line_combined, pattern_im\n",
    "\n",
    "# Create animation\n",
    "frame_step = 20\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(0, min(r_all.shape[1], 20000), frame_step),  # Limit to 1000 frames for performance\n",
    "    interval=50,\n",
    "    blit=True,\n",
    "    repeat=True,\n",
    " )\n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ani.event_source.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4475df",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "ani.save(os.path.join(save_dir, f'pg_PI_feedback_{timestamp}.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(f\"Animation saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3586bd",
   "metadata": {},
   "source": [
    "##### With random feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ef04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wgp_L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59184c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_s = min(T, 10)\n",
    "n_steps = int(T_s/dt)\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "Wgp_L_rand = rng.normal(loc=0.0, scale=0.05, size=(N, Nh))\n",
    "Wgp_L_rand = np.maximum(Wgp_L_rand, 0.0)\n",
    "col_norms = np.linalg.norm(Wgp_L_rand, axis=0, keepdims=True)\n",
    "col_norms[col_norms == 0] = 1.0\n",
    "Wgp_L_rand /= col_norms\n",
    "Wgp_R_rand = rng.normal(loc=0.0, scale=0.05, size=(N, Nh))\n",
    "Wgp_R_rand = np.maximum(Wgp_R_rand, 0.0)\n",
    "col_norms_R = np.linalg.norm(Wgp_R_rand, axis=0, keepdims=True)\n",
    "col_norms_R[col_norms_R == 0] = 1.0\n",
    "Wgp_R_rand /= col_norms_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf28f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final learned weights vs random weights\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "im = ax[0].imshow(Wgp_L, aspect='auto', cmap='viridis')\n",
    "fig.colorbar(im, ax=ax[0], label='Weight strength')\n",
    "ax[0].set_title('Final Wgp_L after training')\n",
    "ax[0].set_xlabel('Place cell index')\n",
    "ax[0].set_ylabel('Grid cell index')\n",
    "ax[1].imshow(Wgp_L_rand, aspect='auto', cmap='viridis')\n",
    "fig.colorbar(im, ax=ax[1], label='Weight strength')\n",
    "ax[1].set_title('Random Wgp_L for comparison')\n",
    "ax[1].set_xlabel('Place cell index')\n",
    "ax[1].set_ylabel('Grid cell index')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898be954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with random Wgp_L and Wgp_R\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "\n",
    "# calculate spike counts in each time step\n",
    "s_prev = np.zeros((2*N, 1))      # initial Population activity (256,1)\n",
    "spk = np.zeros((2*N, n_steps))  # Total spiking\n",
    "p_prev = np.zeros((Nh, 1))      # initial Place cell activity\n",
    "for t in range(1, n_steps):\n",
    "    # Hippocampal (place-cell) dynamics\n",
    "    hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "    phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "    p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "    r_place[:, t:t + 1] = p_new\n",
    "    \n",
    "    # two population of neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L_rand @ p_new\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R_rand @ p_new\n",
    "\n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "    spk = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "    r_all[:, t:t + 1] = s_new\n",
    "    s_prev = s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation of neural activity with hippocampal feedback\n",
    "%matplotlib widget\n",
    "fig, (ax, ax_place) = plt.subplots(\n",
    "    2, 1, figsize=(10, 7), gridspec_kw={'height_ratios': [4, 0.8], 'hspace': 0.4}\n",
    " )\n",
    "# Initialize grid-cell activity lines\n",
    "line_left, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'r-', alpha=0.7, label='Left Population')\n",
    "line_right, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'b-', alpha=0.7, label='Right Population')\n",
    "line_combined, = ax.plot(x_prefs, np.zeros_like(x_prefs), 'g-', linewidth=2, label='Combined')\n",
    "# Add position indicator\n",
    "# pos_line = ax.axvline(0, color='k', linestyle='--', alpha=0.5, label='Current Position')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, np.max(r_all) * 2.1)\n",
    "ax.set_autoscalex_on(False)\n",
    "ax.set_autoscaley_on(False)\n",
    "ax.set_xlabel('Position Preference')\n",
    "ax.set_ylabel('Neural Activity')\n",
    "# ax.set_title('1D grid Fiete 2009 x = {}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hippocampal activity heatmap (1D vector displayed as a thin strip)\n",
    "initial_place = r_place[:, 0]\n",
    "initial_vmax = max(initial_place.max(), 1e-9)\n",
    "pattern_im = ax_place.imshow(\n",
    "    initial_place[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    extent=[0, Nh, 0, 1],\n",
    "    vmin=0,\n",
    "    vmax=initial_vmax,\n",
    ")\n",
    "ax_place.set_yticks([])\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_title('Hippocampal activity (current timestep)')\n",
    "ax_place.set_xlim(0, Nh)\n",
    "# 创建垂直colorbar并设置位置\n",
    "cbar = fig.colorbar(pattern_im, ax=ax_place, orientation='vertical', \n",
    "                    pad=0.05, fraction=0.05, shrink=0.8)\n",
    "cbar.set_label('FR(norm)', rotation=270, labelpad=15)\n",
    "# 或者使用set_position调整（单位为图形坐标）\n",
    "# cbar.ax.set_position([0.85, 0.15, 0.02, 0.7])  # [左, 下, 宽, 高]\n",
    "def update(frame):\n",
    "    t_idx = frame\n",
    "        \n",
    "\n",
    "    # Update activity lines\n",
    "    left_activity = r_all[:N, t_idx]\n",
    "    right_activity = r_all[N:, t_idx]\n",
    "    combined_activity = left_activity + right_activity\n",
    "\n",
    "    line_left.set_ydata(left_activity)\n",
    "    line_right.set_ydata(right_activity)\n",
    "    line_combined.set_ydata(combined_activity)\n",
    "    # Update title\n",
    "    ax.set_title(f' t = {dt * t_idx:.4f}s x = {round(x[t_idx], 2)}')\n",
    "    # Update position line\n",
    "    # current_pos = x[t_idx]\n",
    "    # pos_line.set_xdata([current_pos, current_pos])\n",
    "    \n",
    "    # Update hippocampal heatmap\n",
    "    place_activity = r_place[:, t_idx]\n",
    "    vmax = max(place_activity.max(), 1e-9)\n",
    "    pattern_im.set_data(place_activity[None, :])\n",
    "    pattern_im.set_clim(0, vmax)\n",
    "    cbar.update_normal(pattern_im)\n",
    "\n",
    "    return line_left, line_right, line_combined, pattern_im\n",
    "\n",
    "# Create animation\n",
    "frame_step = 20\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(0, min(r_all.shape[1], 20000), frame_step),  # Limit to 1000 frames for performance\n",
    "    interval=50,\n",
    "    blit=True,\n",
    "    repeat=True,\n",
    " )\n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a661b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ani.event_source.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "ani.save(os.path.join(save_dir, f'pg_PI_fixed_rand_feedback_{timestamp}.gif'), writer='pillow', fps=20, dpi=100)\n",
    "print(f\"Animation saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b747d1",
   "metadata": {},
   "source": [
    "### 吸引子分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e916a66",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac33715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity metrics for comparing patterns\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "def euclidean_similarity(v1, v2):\n",
    "    dist = np.linalg.norm(v1 - v2)\n",
    "    # 将距离转换为相似度（0-1范围）\n",
    "    similarity = 1 / (1 + dist)\n",
    "    return similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    计算两个向量的余弦相似度\n",
    "    范围：[-1, 1]，1表示完全相同，0表示正交，-1表示完全相反\n",
    "    \"\"\"\n",
    "    cos_sim = dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d272889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_p_denoise(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, noise_std = 0.2, sim_measure = 'Cosine'):\n",
    "    '''验证学习后的网络的去噪能力\n",
    "    input: 单噪声水平和初始状态\n",
    "    返回噪声后的初始位置细胞状态p_noise,\n",
    "    最终位置细胞状态p_test,\n",
    "    (最后)位置细胞相似度sim, \n",
    "    去噪后的grid活动g_denoised\n",
    "    ----------  \n",
    "   '''\n",
    "    # place cell initial state with noise_std\n",
    "    p_noise = p_org + np.random.normal(0, noise_std, p_org.shape)\n",
    "    p_noise = np.maximum(p_noise, 0)  # ensure non-negative\n",
    "    \n",
    "    # r_test = np.zeros((len(grid_org)*2, 1))\n",
    "\n",
    "    # grid的初始状态\n",
    "    # s_test = np.hstack([grid_org, grid_org]).T.reshape(-1, 1)  # (128, 1)\n",
    "    s_test = np.zeros((len(grid_org)*2,1))\n",
    "    n_steps_test = int(T_max/dt)\n",
    "    v_test = np.zeros(n_steps_test)  # zero velocity for attractor test\n",
    "\n",
    "\n",
    "    # s_test为前一时刻的grid活动\n",
    "    t = 1\n",
    "    sim = 0.0\n",
    "    p_test = p_noise.copy()\n",
    "    while (sim < 0.99) & (t < n_steps_test - 1):\n",
    "        # Grid cell dynamics (no learning, fixed weights)\n",
    "        v_L = 1 - e_mu * v_test[t]\n",
    "        v_R = 1 + e_mu * v_test[t]\n",
    "        \n",
    "        g_LL = W_LL @ s_test[:N]\n",
    "        g_LR = W_LR @ s_test[N:]\n",
    "        g_RR = W_RR @ s_test[N:]\n",
    "        g_RL = W_RL @ s_test[:N]\n",
    "    \n",
    "        G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_test.reshape(-1,1)\n",
    "        G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_test.reshape(-1,1)\n",
    "        \n",
    "        G = np.vstack([G_L, G_R])\n",
    "        F = G * (G >= 0)\n",
    "        \n",
    "        s_new = s_test + F * dt - s_test * dt / tau_s\n",
    "        # grid activity更新并储存\n",
    "        # r_test[:, t] = s_new.flatten()\n",
    "        s_test = s_new\n",
    "        \n",
    "        # Place cell dynamics\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        if sim_measure == 'Eucliean':\n",
    "            sim = euclidean_similarity(p_new, p_org)\n",
    "        elif sim_measure == 'Cosine':\n",
    "            sim = cosine_similarity(p_new, p_org)\n",
    "        t += 1\n",
    "    g_denoised = np.mean(s_new.reshape(2,-1),axis=0)\n",
    "    return p_noise, p_test, sim, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_p_denoise_process(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, noise_std = 0.2, sim_measure = 'Cosine'):\n",
    "    '''验证学习后的网络的去噪能力\n",
    "    在g_p_denoise()的基础上返回每一时刻的sim\n",
    "    p_noise: 去噪声前\n",
    "    p_test: 去噪声后\n",
    "    sim_arr: 相似度数组 shape = (timestamps, 1)\n",
    "    g_denoised: 去噪后的grid活动\n",
    "    -----------\n",
    "    input: 单噪声水平和初始状态\n",
    "    返回噪声后的初始位置细胞状态p_noise,\n",
    "    '''\n",
    "    # place cell initial state with noise_std\n",
    "    p_noise = p_org + np.random.normal(0, noise_std, p_org.shape)\n",
    "    p_noise = np.maximum(p_noise, 0)  # ensure non-negative\n",
    "\n",
    "    # grid的初始状态\n",
    "    # s_test = np.hstack([grid_org, grid_org]).T.reshape(-1, 1)  # (128, 1)\n",
    "    s_test = np.zeros((len(grid_org)*2,1))\n",
    "    n_steps_test = int(T_max/dt)\n",
    "    v_test = np.zeros(n_steps_test)  # zero velocity for attractor test\n",
    "\n",
    "\n",
    "    # s_test为前一时刻的grid活动\n",
    "    t = 1\n",
    "    sim = 0.0\n",
    "    sim_arr = np.zeros(int(T_max/dt))\n",
    "    p_test = p_noise.copy()\n",
    "    while (t < n_steps_test):\n",
    "        # Grid cell dynamics (no learning, fixed weights)\n",
    "        v_L = 1 - e_mu * v_test[t]\n",
    "        v_R = 1 + e_mu * v_test[t]\n",
    "        \n",
    "        g_LL = W_LL @ s_test[:N]\n",
    "        g_LR = W_LR @ s_test[N:]\n",
    "        g_RR = W_RR @ s_test[N:]\n",
    "        g_RL = W_RL @ s_test[:N]\n",
    "    \n",
    "        G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_test.reshape(-1,1)\n",
    "        G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_test.reshape(-1,1)\n",
    "        \n",
    "        G = np.vstack([G_L, G_R])\n",
    "        F = G * (G >= 0)\n",
    "        \n",
    "        s_new = s_test + F * dt - s_test * dt / tau_s\n",
    "        # grid activity更新并储存\n",
    "        # r_test[:, t] = s_new.flatten()\n",
    "        s_test = s_new\n",
    "        \n",
    "        # Place cell dynamics\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        if sim_measure == 'Eucliean':\n",
    "            sim = euclidean_similarity(p_new, p_org)\n",
    "        elif sim_measure == 'Cosine':\n",
    "            sim = cosine_similarity(p_new, p_org)\n",
    "        sim_arr[t] = sim\n",
    "        t += 1\n",
    "    g_denoised = np.mean(s_new.reshape(2,-1),axis=0)\n",
    "    return p_noise, p_test, sim_arr, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attractor_test1(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, Nrun = 100,noise_stds = [2], sim_measure = 'Cosine'):\n",
    "    \n",
    "    '''验证多个噪声强度下网络的去噪能力\n",
    "    input: single pattern grid_org, p_org\n",
    "    output: p_noise, p_denoised, p_sim, g_denoised'''\n",
    "    Nn = len(noise_stds)\n",
    "    # n_steps_test = int(T_max / dt)\n",
    "    p_sim = np.zeros((Nrun, Nn))  # collect p similarity over time_steps\n",
    "    for n in range(Nn):\n",
    "        noise_std = noise_stds[n]\n",
    "        for r in range(Nrun):\n",
    "            p_noise, p_denoised, sim, g_denoised = g_p_denoise(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max, dt, noise_std, sim_measure)\n",
    "            p_sim[r, n] = sim\n",
    "    \n",
    "    return p_noise, p_denoised, p_sim, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attractor_test2(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, Nrun = 100,noise_stds = [2], sim_measure = 'Cosine'):\n",
    "    '''验证多个噪声强度下网络的去噪能力，并返回每一时刻的相似度变化曲线\n",
    "    input: single pattern grid_org, p_org\n",
    "    output: p_noise, p_denoised, p_sim_array, g_denoised'''\n",
    "    Nn = len(noise_stds)\n",
    "    n_steps_test = int(T_max / dt)\n",
    "    p_sim_all = np.zeros((Nrun, Nn, n_steps_test))  # collect p similarity over time_steps\n",
    "    for n in range(Nn):\n",
    "        noise_std = noise_stds[n]\n",
    "        for r in range(Nrun):\n",
    "            p_noise, p_denoised, sim_array, g_denoised = g_p_denoise_process(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max, dt, noise_std, sim_measure)\n",
    "            p_sim_all[r, n, :] = sim_array\n",
    "    \n",
    "    return p_noise, p_denoised, p_sim_all, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4815b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_p_denoise_batch(grid_org, p_org, Wgp_L, Wgp_R, W_pg, \n",
    "                      T_max=2, dt=0.01, noise_std=0.2, \n",
    "                      batch_size=100, sim_measure='Cosine', \n",
    "                      check_interval=50):\n",
    "    '''\n",
    "    向量化批处理版本的去噪验证函数\n",
    "    Efficiently processes [batch_size] samples in parallel.\n",
    "    '''\n",
    "    # 1. 维度推断与初始化\n",
    "    N_steps_test = int(T_max / dt)\n",
    "    N_grid = len(grid_org)\n",
    "    N_place = len(p_org)\n",
    "    \n",
    "    # 构建 Batch 初始状态\n",
    "    # Target pattern (N_place, 1) 用于广播计算相似度\n",
    "    p_target = p_org.reshape(-1, 1)\n",
    "    \n",
    "    # 批量生成噪声: (N_place, Batch_Size)\n",
    "    noise_matrix = np.random.normal(0, noise_std, (N_place, batch_size))\n",
    "    p_noise_batch = np.maximum(p_target + noise_matrix, 0)\n",
    "    p_test_batch = p_noise_batch.copy()\n",
    "    \n",
    "    # Grid 初始状态 (2*N_grid, Batch_Size)\n",
    "    # 假设 grid 初始为 0 (根据原代码)\n",
    "    s_test_batch = np.zeros((2 * N_grid, batch_size))\n",
    "    \n",
    "    # 速度设为 0，标量即可，无需数组\n",
    "    v_val = 0.0 \n",
    "    \n",
    "    # 预计算常量，避免循环内重复索引\n",
    "    v_L = 1 - e_mu * v_val\n",
    "    v_R = 1 + e_mu * v_val\n",
    "    \n",
    "    # 广播 envelope beta_0: (N, 1)\n",
    "    # 假设 envelope 是 (N, 1) 或 (N,)，确保它是 (N, 1) 以便广播\n",
    "    env_b0 = (envelope * beta_0).reshape(-1, 1)\n",
    "\n",
    "    t = 0\n",
    "    sims = np.zeros(batch_size)\n",
    "    \n",
    "    # 2. 动力学循环\n",
    "    # 为了最大化 Batch 效率，通常不针对单个样本做 Early Stopping\n",
    "    # 而是当所有样本都收敛，或达到最大步数时退出。\n",
    "    # 这里为了速度，我们只在 check_interval 步数时检查。\n",
    "    \n",
    "    for t in range(N_steps_test):\n",
    "        # --- Grid Cell Dynamics ---\n",
    "        # Matrix Ops: (N, N) @ (N, Batch) -> (N, Batch)\n",
    "        g_LL = W_LL @ s_test_batch[:N]\n",
    "        g_LR = W_LR @ s_test_batch[N:]\n",
    "        g_RR = W_RR @ s_test_batch[N:]\n",
    "        g_RL = W_RL @ s_test_batch[:N]\n",
    "        \n",
    "        # Place -> Grid Input\n",
    "        # (N, N_p) @ (N_p, Batch) -> (N, Batch)\n",
    "        inp_gp_L = g_gp * (Wgp_L @ p_test_batch)\n",
    "        inp_gp_R = g_gp * (Wgp_R @ p_test_batch)\n",
    "        \n",
    "        # Total Grid Input\n",
    "        G_L = v_L * (g_LL + g_LR + env_b0) + inp_gp_L\n",
    "        G_R = v_R * (g_RR + g_RL + env_b0) + inp_gp_R\n",
    "        \n",
    "        G = np.vstack([G_L, G_R])\n",
    "        F = G * (G >= 0) # ReLU\n",
    "        \n",
    "        # Euler Integration\n",
    "        s_test_batch += (F * dt) - (s_test_batch * dt / tau_s)\n",
    "        \n",
    "        # --- Place Cell Dynamics ---\n",
    "        # Grid -> Place Input\n",
    "        hippo_drive = gain_pg * (W_pg @ s_test_batch) + Iext2\n",
    "        \n",
    "        phi_term = np.maximum(hippo_drive - theta, 0) # ReLU\n",
    "        \n",
    "        # Place Update\n",
    "        p_test_batch += (dt / tau_h) * (-p_test_batch + phi_term)\n",
    "        \n",
    "        # --- Efficiency Check ---\n",
    "        # 仅每隔 check_interval 步计算一次相似度\n",
    "        if t % check_interval == 0 and t > 0:\n",
    "            if sim_measure == 'Cosine':\n",
    "                # Vectorized Cosine Similarity\n",
    "                # p_test_batch: (M, B), p_target: (M, 1)\n",
    "                dot_prod = np.sum(p_test_batch * p_target, axis=0) # (B,)\n",
    "                norm_batch = np.linalg.norm(p_test_batch, axis=0)\n",
    "                norm_target = np.linalg.norm(p_target) # Scalar\n",
    "                \n",
    "                sims = dot_prod / (norm_batch * norm_target + 1e-9)\n",
    "            \n",
    "            # 如果这批数据里最差的一个都已经 > 0.99，则提前退出\n",
    "            if np.min(sims) > 0.99:\n",
    "                break\n",
    "\n",
    "    # 3. Final Similarity Calculation\n",
    "    if sim_measure == 'Cosine':\n",
    "        dot_prod = np.sum(p_test_batch * p_target, axis=0)\n",
    "        norm_batch = np.linalg.norm(p_test_batch, axis=0)\n",
    "        norm_target = np.linalg.norm(p_target)\n",
    "        sims = dot_prod / (norm_batch * norm_target + 1e-9)\n",
    "        \n",
    "    # Grid denoised: average pooling\n",
    "    # reshape to (2, N, Batch) then mean over axis 0 -> (N, Batch)\n",
    "    g_denoised_batch = np.mean(s_test_batch.reshape(2, N_grid, -1), axis=0)\n",
    "    \n",
    "    return p_noise_batch, p_test_batch, sims, g_denoised_batch\n",
    "\n",
    "def attractor_test_optimized(grid_org, p_org, Wgp_L, Wgp_R, W_pg, \n",
    "                             T_max=2, dt=0.01, Nrun=100, \n",
    "                             noise_stds=[0.5], sim_measure='Cosine'):\n",
    "    '''\n",
    "    优化batch后的主测试函数\n",
    "    '''\n",
    "    Ngrid = len(grid_org)\n",
    "    Nn = len(noise_stds)\n",
    "    # 结果矩阵: (Nrun, N_noise_levels)\n",
    "    p_sim_results = np.zeros((Nrun, Nn))\n",
    "    g_denoised_results = np.zeros((Nn, Ngrid,Nrun))\n",
    "    # 占位符，用于返回最后一次循环的数据以供可视化\n",
    "    last_p_noise = None\n",
    "    last_p_denoised = None\n",
    "    last_g_denoised = None\n",
    "    \n",
    "    # print(f\"Starting optimized batch test (Batch Size={Nrun})...\")\n",
    "    \n",
    "    for i, noise_std in enumerate(noise_stds):\n",
    "        # 对每个噪声水平，直接运行一次 Batch\n",
    "        # 将 Nrun 直接作为 batch_size 传入，一次性算出所有结果\n",
    "        p_noise, p_denoised, sims, g_denoised = g_p_denoise_batch(\n",
    "            grid_org, p_org, Wgp_L, Wgp_R, W_pg, \n",
    "            T_max=T_max, dt=dt, noise_std=noise_std, \n",
    "            batch_size=Nrun, sim_measure=sim_measure,\n",
    "            check_interval=50  # 降低检测频率\n",
    "        )\n",
    "        g_denoised_results[i,:,:]= g_denoised   # (N, Batch)\n",
    "        p_sim_results[:, i] = sims\n",
    "        \n",
    "        # 保存最后一次的结果\n",
    "        last_p_noise = p_noise\n",
    "        last_p_denoised = p_denoised\n",
    "        # last_g_denoised = g_denoised\n",
    "        \n",
    "    # print(\"Done.\")\n",
    "    return last_p_noise, last_p_denoised, p_sim_results, g_denoised_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e5d47",
   "metadata": {},
   "source": [
    "#### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793fef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test trained patterns\n",
    "g_idxed = g_indexes.copy\n",
    "p_tests = []\n",
    "T_s = 5   # 保证收敛\n",
    "dt = 0.0005\n",
    "n_steps_test = int(T_s/dt)\n",
    "for g_id in g_indexes:\n",
    "    grid_org = pattern_average_activity[g_id].reshape(-1,1)\n",
    "    s_new = np.vstack([grid_org, grid_org])   # initialize with previous g\n",
    "    # print(s_new.shape)\n",
    "    p_hist = np.zeros((Nh,n_steps_test))\n",
    "    p_test = np.zeros((Nh, )) \n",
    "    n_steps_test = int(T_s/dt)\n",
    "    # p_hist = np.zeros((Nh,n_steps_test))\n",
    "    for t in range(n_steps_test):\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        p_hist[:,t] = p_test\n",
    "    # print(p_test.shape)\n",
    "    p_tests.append(p_test)\n",
    "p_tests = np.stack(p_tests)  # (Npatts, Nh)\n",
    "\n",
    "# # Visualize\n",
    "# plt.figure(figsize=(10,4))\n",
    "# # 只打印最后一个pattern的place cell活动随时间变化\n",
    "# plt.plot(np.mean(p_hist, axis=0))\n",
    "# plt.xlabel('Time Step')\n",
    "# plt.ylabel('Mean Place Cell Activity')  \n",
    "# plt.title('Place Cell Activity Over Time for Archetype')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c28d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Vectorized Batch Generation of Place Patterns ---\n",
    "\n",
    "# 1. 准备数据: 将所有 Grid Pattern 堆叠成 Batch 矩阵\n",
    "# pattern_average_activity 应该是一个 list of arrays 或者 (N_patterns, N_grid) matrix\n",
    "# 我们需要构建 (2*Nh, N_patterns) 的输入矩阵 S\n",
    "if isinstance(pattern_average_activity, list):\n",
    "    # 如果是 list，先 stack 成 (N_patterns, N_grid)\n",
    "    grid_patterns = np.stack(pattern_average_activity).T # (N_grid, N_patterns)\n",
    "else:\n",
    "    # 如果已经是 array (N_patterns, N_grid)，转置它\n",
    "    grid_patterns = pattern_average_activity.T\n",
    "    \n",
    "N_grid = grid_patterns.shape[0]\n",
    "N_bat = grid_patterns.shape[1]\n",
    "\n",
    "# 构建 s_new_batch (2*N_grid, N_patterns)\n",
    "# 左右 ring 的初始输入是一样的\n",
    "s_new_batch = np.vstack([grid_patterns, grid_patterns])\n",
    "\n",
    "# parameters\n",
    "T_s = 5       # 保证收敛\n",
    "dt = 0.0005\n",
    "n_steps_test = int(T_s/dt)\n",
    "\n",
    "# 2. 初始化 Batch 变量\n",
    "# p_test_batch: (Nh, N_patterns)\n",
    "p_test_batch = np.zeros((Nh, N_bat)) \n",
    "# 预先处理 Iext2 的广播形状 (Nh, 1)\n",
    "Iext2_batch = 0  # Iext2 if Iext2.ndim > 1 else Iext2.reshape(-1, 1)\n",
    "\n",
    "# 3. 动力学循环 (Vectorized)\n",
    "print(f\"Generating place codes for {N_bat} patterns in batch...\")\n",
    "for t in range(n_steps_test):\n",
    "    # Matrix Mul: (Nh, 2Ng) @ (2Ng, N_bat) -> (Nh, N_bat)\n",
    "    hippo_drive = gain_pg * (W_pg @ s_new_batch) + Iext2_batch\n",
    "    \n",
    "    # Batch ReLU\n",
    "    phi_term = np.maximum(hippo_drive - theta, 0)\n",
    "    \n",
    "    # Batch Euler Update\n",
    "    # p_test_batch += (dt / tau_h) * (-p_test_batch + phi_term)\n",
    "    # 为了避免创建临时大数组，使用原地操作通常更快：\n",
    "    delta = -p_test_batch\n",
    "    delta += phi_term\n",
    "    delta *= (dt / tau_h)\n",
    "    p_test_batch += delta\n",
    "\n",
    "# 4. 结果整理\n",
    "# 转置回 (N_patterns, Nh) 以匹配原始输出格式\n",
    "p_all = p_test_batch.T\n",
    "\n",
    "print(f\"Done. Output shape: {p_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save average denoising results of  multiple runs\n",
    "ls_noise = [0.5, 1, 2, 3]\n",
    "Nrun = 500\n",
    "p_sim_all = []\n",
    "for i, g_id in enumerate(g_indexes):\n",
    "    _, _, p_sim, _ = attractor_test1(\n",
    "        grid_org=pattern_average_activity[g_id].reshape(-1,1), \n",
    "        p_org=p_all[i], \n",
    "        Wgp_L=Wgp_L, Wgp_R=Wgp_R, W_pg=W_pg, \n",
    "        T_max=5, dt=0.0005, Nrun=Nrun, noise_stds=ls_noise, sim_measure='Cosine'\n",
    "    )\n",
    "    p_sim_all.append(p_sim)\n",
    "p_sim_all = np.stack(p_sim_all)  # (Npatts, Nrun, Nnoise)\n",
    "p_sim_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d621a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_mean = np.mean(p_sim_all, axis=1)  # (Npatts, Nnoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a54662",
   "metadata": {},
   "source": [
    "Batch Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3785561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test trained patterns\n",
    "g_ind = [i for i in range(len(pattern_average_activity))]\n",
    "p_all = []\n",
    "T_s = 5   # 保证收敛\n",
    "dt = 0.0005\n",
    "n_steps_test = int(T_s/dt)\n",
    "for g_id in g_ind:\n",
    "    grid_org = pattern_average_activity[g_id].reshape(-1,1)\n",
    "    s_new = np.vstack([grid_org, grid_org])   # initialize with previous g\n",
    "    # print(s_new.shape)\n",
    "    p_hist = np.zeros((Nh,n_steps_test))\n",
    "    p_test = np.zeros((Nh, )) \n",
    "    n_steps_test = int(T_s/dt)\n",
    "    # p_hist = np.zeros((Nh,n_steps_test))\n",
    "    for t in range(n_steps_test):\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        p_hist[:,t] = p_test\n",
    "    # print(p_test.shape)\n",
    "    p_all.append(p_test)\n",
    "p_all = np.stack(p_all)  # (Npatts, Nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_all = []\n",
    "# g_ind = g_indexes.copy()\n",
    "g_ind = [i for i in range(len(pattern_average_activity))]\n",
    "ls_noise = [0.5, 2, 5, 10]\n",
    "for i, g_id in enumerate(g_ind):\n",
    "    _, _, p_sims, _ = attractor_test_optimized(\n",
    "        grid_org=pattern_average_activity[g_id], # 示例\n",
    "        p_org=p_all[i],   # 示例\n",
    "        Wgp_L=Wgp_L, Wgp_R=Wgp_R, W_pg=W_pg,\n",
    "        T_max=2, dt=0.01, Nrun=500,   # Nrun=500 现在是并行跑的\n",
    "        noise_stds=ls_noise\n",
    "    )\n",
    "    p_sim_all.append(p_sims)\n",
    "p_sim_all = np.stack(p_sim_all)  # (Npatts, Nrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ce657",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_mean = np.mean(p_sim_all, axis=1)  # (Npatts, Nnoise)\n",
    "p_sim_ste = np.std(p_sim_all, axis=1) / np.sqrt(p_sim_all.shape[1])  # (Npatts, Nnoise)\n",
    "p_sim_mean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(8,5))\n",
    "for i in range(p_sim_mean.shape[1]):\n",
    "    ax[0].errorbar(x_prefs, p_sim_mean[:,i], yerr=p_sim_ste[:,i], marker='o', label=f'noise {ls_noise[i]}')\n",
    "ax[0].set_xlabel('Position Preference')\n",
    "ax[0].set_ylabel('Mean Similarity')\n",
    "ax[0].set_title('Mean Similarity vs Noise Level for Each Pattern')\n",
    "ax[0].legend()\n",
    "# plot trained grid_org\n",
    "for i, g_id in enumerate(g_indexes):\n",
    "    ax[1].plot(x_prefs, pattern_average_activity[g_id], label=f'Pattern {g_id}')\n",
    "ax[1].set_xlabel('Position Preference')\n",
    "ax[1].set_ylabel('Grid Cell Activity')\n",
    "ax[1].set_title('Trained Grid Cell Patterns')\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_mean = np.mean(p_sim_all, axis=1)  # (Npatts, Nnoise)\n",
    "p_sim_ste = np.std(p_sim_all, axis=1) / np.sqrt(p_sim_all.shape[1])  # (Npatts, Nnoise)\n",
    "p_sim_mean.shape\n",
    "plt.figure(figsize=(8,5))\n",
    "for i in range(p_sim_mean.shape[0]):\n",
    "    plt.errorbar(ls_noise, p_sim_mean[i,:], yerr=p_sim_ste[i,:], marker='o', label=f'Pattern {g_indexes[i]}')\n",
    "plt.xlabel('Noise Std Dev')\n",
    "plt.ylabel('Mean Similarity')\n",
    "plt.title('Mean Similarity vs Noise Level for Each Pattern')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# plot grid patterns\n",
    "for g_id in g_indexes:\n",
    "    plt.plot(pattern_average_activity[g_id], label=f'Grid Pattern {g_id}')\n",
    "plt.xlabel('Neuron Index')\n",
    "plt.ylabel('Average Activity')\n",
    "plt.title('Learned Grid Cell Patterns')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d145860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8cd444",
   "metadata": {},
   "source": [
    "##### Aternative: |Batch2: 超大矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dynamics_batch(s_init, p_init, p_target, \n",
    "                       Wgp_L, Wgp_R, W_pg, \n",
    "                       T_max=2, dt=0.01, check_interval=50, sim_measure='Cosine'):\n",
    "    '''\n",
    "    核心动力学引擎：接收完全构建好的批量数据进行迭代\n",
    "    \n",
    "    Inputs:\n",
    "        s_init: (2*N_grid, Total_Batch) Grid初始化状态\n",
    "        p_init: (N_place, Total_Batch) Place初始化状态\n",
    "        p_target: (N_place, Total_Batch) 对应的目标模式，用于计算相似度\n",
    "    Returns:\n",
    "        p_final: (N_place, Total_Batch) 最终状态\n",
    "        sims: (Total_Batch,) 每一列对应的最终相似度\n",
    "    '''\n",
    "    N_steps = int(T_max / dt)\n",
    "    N_grid_2 = s_init.shape[0]\n",
    "    N_place = p_init.shape[0]\n",
    "    batch_size = s_init.shape[1]\n",
    "    \n",
    "    # 状态变量复印\n",
    "    s_test = s_init.copy()\n",
    "    p_test = p_init.copy()\n",
    "    \n",
    "    # 常量准备\n",
    "    # 假设 envelope, beta_0 是全局变量，且适配广播\n",
    "    env_b0 = (envelope * beta_0).reshape(-1, 1)\n",
    "    # 假设 v=0，预计算增益\n",
    "    v_L = 1.0\n",
    "    v_R = 1.0\n",
    "\n",
    "    sims = np.zeros(batch_size)\n",
    "    \n",
    "    # --- 动力学循环 ---\n",
    "    for t in range(N_steps):\n",
    "        # 1. Grid Cell Dynamics\n",
    "        # (N, N) @ (N, Batch) -> (N, Batch)\n",
    "        g_LL = W_LL @ s_test[:N]\n",
    "        g_LR = W_LR @ s_test[N:]\n",
    "        g_RR = W_RR @ s_test[N:]\n",
    "        g_RL = W_RL @ s_test[:N]\n",
    "        \n",
    "        # Place -> Grid Input\n",
    "        inp_gp_L = g_gp * (Wgp_L @ p_test)\n",
    "        inp_gp_R = g_gp * (Wgp_R @ p_test)\n",
    "        \n",
    "        G_L = v_L * (g_LL + g_LR + env_b0) + inp_gp_L\n",
    "        G_R = v_R * (g_RR + g_RL + env_b0) + inp_gp_R\n",
    "        \n",
    "        G = np.vstack([G_L, G_R])\n",
    "        F = G * (G >= 0) # ReLU\n",
    "        \n",
    "        s_test += (F * dt) - (s_test * dt / tau_s)\n",
    "        \n",
    "        # 2. Place Cell Dynamics\n",
    "        hippo_drive = gain_pg * (W_pg @ s_test) + Iext2\n",
    "        phi_term = np.maximum(hippo_drive - theta, 0)\n",
    "        p_test += (dt / tau_h) * (-p_test + phi_term)\n",
    "        \n",
    "        # 3. 稀疏检测 (Efficiency Check)\n",
    "        if t % check_interval == 0 and t > 0:\n",
    "            if sim_measure == 'Cosine':\n",
    "                # 针对每一列，计算其与对应 target 列的相似度\n",
    "                # p_test: (M, B), p_target: (M, B)\n",
    "                dot_prod = np.sum(p_test * p_target, axis=0) # (B,)\n",
    "                norm_test = np.linalg.norm(p_test, axis=0)\n",
    "                norm_target = np.linalg.norm(p_target, axis=0)\n",
    "                \n",
    "                sims = dot_prod / (norm_test * norm_target + 1e-9)\n",
    "            \n",
    "            # 如果所有样本都收敛 (min > 0.99)，则提取退出\n",
    "            # 注意：如果混合了很难收敛的高噪声样本，这里可能不会触发退出，\n",
    "            # 如果想让容易的先“完成”，代码会复杂一些，通常直接跑完更利于并行\n",
    "            if np.min(sims) > 0.99:\n",
    "                break\n",
    "                \n",
    "    # Final Similarity\n",
    "    if sim_measure == 'Cosine':\n",
    "        dot_prod = np.sum(p_test * p_target, axis=0)\n",
    "        norm_test = np.linalg.norm(p_test, axis=0)\n",
    "        norm_target = np.linalg.norm(p_target, axis=0)\n",
    "        sims = dot_prod / (norm_test * norm_target + 1e-9)\n",
    "        \n",
    "    return p_test, sims, s_test\n",
    "\n",
    "def attractor_test_parallel_all(grid_orgs, p_orgs, \n",
    "                                Wgp_L, Wgp_R, W_pg, \n",
    "                                noise_stds=[0.5, 1.0, 2.0], \n",
    "                                Nrun=100, T_max=2, dt=0.01):\n",
    "    '''\n",
    "    全混并行测试器：\n",
    "    同时迭代：[所有 Patterns] x [所有 Noise Levels] x [Nrun]\n",
    "    \n",
    "    Inputs:\n",
    "        grid_orgs: (N_grid, N_patterns) 或 (N_grid,) 单个向量\n",
    "        p_orgs:    (N_place, N_patterns) 或 (N_place,) 单个向量\n",
    "        noise_stds: list of noise levels\n",
    "        Nrun: runs per condition\n",
    "    '''\n",
    "    # 1. 统一维度处理\n",
    "    if grid_orgs.ndim == 1: grid_orgs = grid_orgs[:, None]\n",
    "    if p_orgs.ndim == 1:    p_orgs = p_orgs[:, None]\n",
    "    \n",
    "    N_grid, N_patterns = grid_orgs.shape\n",
    "    N_place = p_orgs.shape[0]\n",
    "    N_noises = len(noise_stds)\n",
    "    \n",
    "    Total_Batch = N_patterns * N_noises * Nrun\n",
    "    print(f\"Building Super Batch: {N_patterns} patterns x {N_noises} noises x {Nrun} runs = {Total_Batch} samples\")\n",
    "    \n",
    "    # 2. 构建 Super Batch 数据\n",
    "    # 我们需要构建 (Dim, Total_Batch) 的矩阵\n",
    "    \n",
    "    # 策略：外层循环为 Pattern，中层为 Noise，内层为 Runs\n",
    "    # 为了利用 numpy 的 repeat/tile，我们先构建索引逻辑\n",
    "    \n",
    "    # A. 目标矩阵 p_target_batch\n",
    "    # 每个 Pattern 重复 (N_noises * Nrun) 次\n",
    "    # p_orgs: (N_place, N_patterns) -> repeat axis 1 -> (N_place, Total_Batch)\n",
    "    p_target_batch = np.repeat(p_orgs, N_noises * Nrun, axis=1)\n",
    "    \n",
    "    # B. 噪声强度向量 scales\n",
    "    # 对于每个 Pattern，噪声序列是 [std1...std1, std2...std2, ...]\n",
    "    # 先构建单个 Pattern 的噪声序列 (N_noises * Nrun)\n",
    "    noise_seq_single = np.repeat(noise_stds, Nrun) \n",
    "    # 再将这个序列重复 N_patterns 次\n",
    "    noise_scales = np.tile(noise_seq_single, N_patterns) # (Total_Batch,)\n",
    "    \n",
    "    # C. 初始状态 p_init_batch\n",
    "    # 生成基础高斯噪声\n",
    "    base_noise = np.random.normal(0, 1, (N_place, Total_Batch))\n",
    "    # 应用强度\n",
    "    scaled_noise = base_noise * noise_scales.reshape(1, -1)\n",
    "    # 叠加到目标上\n",
    "    p_init_batch = np.maximum(p_target_batch + scaled_noise, 0)\n",
    "    \n",
    "    # D. Grid 初始状态\n",
    "    # 假设 Grid 初始全 0\n",
    "    # 如果 Grid 也需要像 Place 那样设初值 (通常 attract test 设为 0 或对应 grid pattern)，\n",
    "    # 如果是设为对应 Grid Pattern:\n",
    "    # grid_target_batch = np.repeat(grid_orgs, N_noises * Nrun, axis=1)\n",
    "    # s_init_batch = np.vstack([grid_target_batch, grid_target_batch]) \n",
    "    # 这里沿用原代码逻辑：全 0\n",
    "    s_init_batch = np.zeros((2 * N_grid, Total_Batch))\n",
    "    \n",
    "    # 3. 一次性运行动力学\n",
    "    p_final, sims_flat, s_final = run_dynamics_batch(\n",
    "        s_init_batch, p_init_batch, p_target_batch,\n",
    "        Wgp_L, Wgp_R, W_pg,\n",
    "        T_max=T_max, dt=dt\n",
    "    )\n",
    "    \n",
    "    # 4. 结果重组 (Reshape Results)\n",
    "    # 输出结果应该是按层级组织的，方便后续切片\n",
    "    # 原始 flat 顺序是: P1_N1_runs ... P1_N2_runs ... P2_N1_runs ...\n",
    "    # 目标形状: (N_patterns, N_noises, Nrun)\n",
    "    \n",
    "    sim_results = sims_flat.reshape(N_patterns, N_noises, Nrun)\n",
    "    \n",
    "    # 也可以计算去噪后的 grid pattern\n",
    "    g_final_batch = np.mean(s_final.reshape(2, N_grid, Total_Batch), axis=0)\n",
    "    g_denoised_reshaped = g_final_batch.reshape(N_grid, N_patterns, N_noises, Nrun)\n",
    "    \n",
    "    return sim_results, g_denoised_reshaped, p_final # p_final 也可以 reshape 如果需要\n",
    "# 准备数据：假设你要测试前 10 个记忆模式\n",
    "curr_grid_patterns = patterns_grid[:, :10] # (N_grid, 10)\n",
    "curr_place_patterns = patterns_place[:, :10] # (N_place, 10)\n",
    "curr_noises = [0.5, 1, 2, 3]\n",
    "\n",
    "# 一键运行\n",
    "sim_matrix, _, _ = attractor_test_parallel_all(\n",
    "    curr_grid_patterns, \n",
    "    curr_place_patterns,\n",
    "    Wgp_L, Wgp_R, W_pg,\n",
    "    noise_stds=curr_noises,\n",
    "    Nrun=500,  # 这里的 Nrun 是每个组合跑 500 次\n",
    "    T_max=2\n",
    ")\n",
    "\n",
    "# 结果分析方便多了\n",
    "# sim_matrix 的形状是 (10, 4, 500) -> (Pattern, Noise, Run)\n",
    "\n",
    "# 例如：绘制所有 Pattern 在噪声 2.0 下的平均表现\n",
    "# Index 2 对应噪声 2.0 (0.5, 1.0, 2.0)\n",
    "avg_sim_noise_2 = np.mean(sim_matrix[:, 2, :], axis=1) # (10,) 每个 Pattern 的平均分\n",
    "print(\"各模式在噪声 2.0 下的平均相似度:\", avg_sim_noise_2)\n",
    "\n",
    "# 例如：绘制全噪声下的总体 Tuning Curve 表现 (平均掉 Pattern 和 Run)\n",
    "global_avg = np.mean(sim_matrix, axis=(0, 2)) # (4,) 对应 4 个噪声水平\n",
    "plt.plot(curr_noises, global_avg, 'o-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc20d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save temporal dynamics of denoising process under different noise levels\n",
    "ls_noise = [0,2,4,8,10]\n",
    "T_max = 1.5\n",
    "dt = 0.0005\n",
    "g_idxed = g_indexes\n",
    "\n",
    "grid_global_min = 0.0\n",
    "grid_global_max = pattern_average_activity[g_idxed, :].max()\n",
    "place_global_max = p_tests[:len(g_idxed), :].max()\n",
    "time_axis = np.arange(int(T_max / dt)) * dt\n",
    "\n",
    "p_sim_all = []\n",
    "g_denoised_all = []\n",
    "for i,g_id in enumerate(g_indexes):\n",
    "    grid_org = pattern_average_activity[g_id]\n",
    "    p_org = p_tests[i]\n",
    "    # normalize grid_org\n",
    "    p_noise, p_denoised, p_sim, g_denoise = attractor_test2(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = T_max, dt = dt,\n",
    "                            Nrun = 100,noise_stds = ls_noise, sim_measure = 'Cosine')\n",
    "    p_sim_all.append(p_sim)\n",
    "    g_denoised_all.append(g_denoise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3cc6d",
   "metadata": {},
   "source": [
    "##### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exoprt results\n",
    "time = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "# export_dir = os.path.join(folder_path, 'exports', f'pg_Mul-1D_denoise_{N}_{time}')\n",
    "# os.makedirs(export_dir, exist_ok=True)\n",
    "export_dir = r'D:\\\\prob_learning\\\\grid_cell\\\\202601_Loop model\\\\visualization\\\\exports\\\\pg_Mul-1D_32_0205_sparse'\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'p_sim_all.npy'),\n",
    "    np.array(p_sim_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'g_denoised_all.npy'),\n",
    "    np.array(g_denoised_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d320c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,g_id in enumerate(g_indexes):\n",
    "    grid_org = pattern_average_activity[g_id]\n",
    "    p_org = p_tests[i]\n",
    "    p_sim = p_sim_all[i]\n",
    "    g_denoise = g_denoised_all[i]\n",
    "     # Plotting\n",
    "    fig = plt.figure(figsize=(13.5, 5))\n",
    "    gs = fig.add_gridspec(2, 2, width_ratios=[1, 2], height_ratios=[1, 1],\n",
    "                          wspace=0.3, hspace=0.55)\n",
    "    ax_grid = fig.add_subplot(gs[0, 0])\n",
    "    ax_place = fig.add_subplot(gs[1, 0])\n",
    "    ax_sim = fig.add_subplot(gs[:, 1])\n",
    "\n",
    "    ax_grid.plot(np.arange(N), grid_org, color='steelblue', linewidth=2, label='Original\\n Grid')\n",
    "    ax_grid.plot(np.arange(N), g_denoise, color='orange', linestyle='--', linewidth=2, label='Denoised\\n Grid')\n",
    "    ax_grid.legend(bbox_to_anchor = (1.35,0.95), loc='upper right', fontsize='small')\n",
    "    ax_grid.set_xlim(0, N - 1)\n",
    "    ax_grid.set_ylim(grid_global_min, grid_global_max * 1.05)\n",
    "    ax_grid.set_title(f'Grid pattern (g_idx={g_id})')\n",
    "    ax_grid.set_xlabel('Neuron index')\n",
    "    ax_grid.set_ylabel('Activity')\n",
    "\n",
    "    im = ax_place.imshow(\n",
    "        p_org[None, :],\n",
    "        aspect='auto',\n",
    "        cmap='gray',\n",
    "        vmin=0.0,\n",
    "        vmax=place_global_max * 1.05,\n",
    "        extent=[0, Nh, 0, 1],\n",
    "    )\n",
    "    ax_place.set_title('Place pattern', pad=12)\n",
    "    ax_place.set_xlabel('Place cell index')\n",
    "    ax_place.set_yticks([])\n",
    "    plt.colorbar(im, ax=ax_place, orientation='horizontal', pad=0.35, fraction=0.2, label='Activity')\n",
    "\n",
    "    ax_sim.set_title(f'Attractor Test for Archetype {g_id}')\n",
    "    ax_sim.set_xlabel('Time (s)')\n",
    "    ax_sim.set_ylabel('Similarity')\n",
    "    ax_sim.set_ylim(0, 1.1)\n",
    "    ax_sim.grid(True, color='grey', ls='dashed', lw=1, alpha=0.3)\n",
    "\n",
    "    for noise_idx, noise_std in enumerate(ls_noise):\n",
    "        mean_sim = np.mean(p_sim[:, noise_idx, :], axis=0)\n",
    "        std_sim = np.std(p_sim[:, noise_idx, :], axis=0)\n",
    "        ax_sim.fill_between(time_axis, mean_sim - std_sim, mean_sim + std_sim, alpha=0.15)\n",
    "        ax_sim.plot(time_axis, mean_sim, label=f'STD={noise_std}', linewidth=2)\n",
    "\n",
    "    ax_sim.legend(loc='lower right', fontsize='small')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\n",
    "        os.path.join(folder_path, f'g-org_learned_{g_id}.png'),\n",
    "        bbox_inches='tight',\n",
    "        pad_inches=0.1\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2b57d",
   "metadata": {},
   "source": [
    "## Train and Test (Integrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generate_place_patterns(pattern_average_activity, W_pg, T_s=5, dt=0.0005):\n",
    "    '''\n",
    "    test trained patterns\n",
    "    '''\n",
    "    g_ind = [i for i in range(len(pattern_average_activity))]\n",
    "    p_all = []\n",
    "    n_steps_test = int(T_s/dt)\n",
    "    for g_id in g_ind:\n",
    "        grid_org = pattern_average_activity[g_id].reshape(-1,1)\n",
    "        s_new = np.vstack([grid_org, grid_org])   # initialize with previous g\n",
    "        # print(s_new.shape)\n",
    "        p_hist = np.zeros((Nh,n_steps_test))\n",
    "        p_test = np.zeros((Nh, )) \n",
    "        n_steps_test = int(T_s/dt)\n",
    "        # p_hist = np.zeros((Nh,n_steps_test))\n",
    "        for t in range(n_steps_test):\n",
    "            hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "            phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "            p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "            # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "            p_test = p_new.flatten()\n",
    "            p_hist[:,t] = p_test\n",
    "        # print(p_test.shape)\n",
    "        p_all.append(p_test)\n",
    "    p_all = np.stack(p_all)  # (Npatts, Nh)\n",
    "    return p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_denoising_patterns(pattern_average_activity, p_all, Wgp_L, Wgp_R, W_pg, g_inx_test,g_inx_train, x_prefs,ls_noise = [0,0.5,5,10], Nrun=500, T_max=2, dt=0.01, plot=True):\n",
    "    '''\n",
    "    plot trained patterns\n",
    "    '''\n",
    "    p_sim_all = []\n",
    "    # g_ind = g_indexes.copy()\n",
    "    # g_ind = \n",
    "    for i, g_id in enumerate(tqdm(g_inx_test, desc=\"Testing patterns\")):\n",
    "        _, _, p_sims, _ = attractor_test_optimized(\n",
    "            grid_org=pattern_average_activity[g_id], # 示例\n",
    "            p_org=p_all[i],   # 示例\n",
    "            Wgp_L=Wgp_L, Wgp_R=Wgp_R, W_pg=W_pg,\n",
    "            T_max=T_max, dt=dt, Nrun=Nrun,   # Nrun=500 现在是并行跑的\n",
    "            noise_stds=ls_noise\n",
    "        )\n",
    "        p_sim_all.append(p_sims)\n",
    "    p_sim_all = np.stack(p_sim_all)  # (Npatts, Nrun\n",
    "    p_sim_mean = np.mean(p_sim_all, axis=1)  # (Npatts, Nnoise)\n",
    "    p_sim_ste = np.std(p_sim_all, axis=1) / np.sqrt(p_sim_all.shape[1])  # (Npatts, Nnoise)\n",
    "    p_sim_mean.shape\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2,1,figsize=(8,5))\n",
    "        for i in range(p_sim_mean.shape[1]):\n",
    "            ax[0].errorbar(x_prefs, p_sim_mean[:,i], yerr=p_sim_ste[:,i], marker='o', label=f'noise {ls_noise[i]}')\n",
    "        ax[0].set_xlabel('Position Preference')\n",
    "        ax[0].set_ylabel('Mean Similarity')\n",
    "        ax[0].set_title('Mean Similarity vs Noise Level for Each Pattern')\n",
    "        ax[0].legend()\n",
    "        # plot trained grid_org\n",
    "        for i, g_id in enumerate(g_inx_train):\n",
    "            ax[1].plot(x_prefs, pattern_average_activity[g_id], label=f'Pattern {g_id}')\n",
    "        ax[1].set_xlabel('Position Preference')\n",
    "        ax[1].set_ylabel('Grid Cell Activity')\n",
    "        ax[1].set_title('Trained Grid Cell Patterns')\n",
    "        ax[1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return p_sim_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6924a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denoising_g_patterns(pattern_average_activity, p_all, Wgp_L, Wgp_R, W_pg, g_inx_test,ls_noise = [0,0.5,5,10], Nrun=500, T_max=2, dt=0.01):\n",
    "    '''\n",
    "    plot trained patterns\n",
    "    '''\n",
    "    # p_sim_all = []\n",
    "    g_denoised_all = []\n",
    "    for i, g_id in enumerate(tqdm(g_inx_test, desc=\"Testing patterns\")):\n",
    "        _, _, _, g_denoised = attractor_test_optimized(\n",
    "            grid_org=pattern_average_activity[g_id], # 示例\n",
    "            p_org=p_all[i],   # 示例\n",
    "            Wgp_L=Wgp_L, Wgp_R=Wgp_R, W_pg=W_pg,\n",
    "            T_max=T_max, dt=dt, Nrun=Nrun,   # Nrun=500 现在是并行跑的\n",
    "            noise_stds=ls_noise\n",
    "        )\n",
    "        # p_sim_all.append(p_sims)\n",
    "        g_denoised_all.append(g_denoised)\n",
    "    \n",
    "    # p_sim_all = np.stack(p_sim_all)  # (Npatts, Nrun\n",
    "    g_denoised_all = np.stack(g_denoised_all)  # (Npatts, Ngrid, Nnoise, Nrun)\n",
    "    \n",
    "    return g_denoised_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denoising_process(pattern_average_activity, p_all, Wgp_L, Wgp_R, W_pg, g_inx_test,g_inx_train, x_prefs,ls_noise = [0,0.5,5,10], Nrun=500, T_max=2, dt=0.01, plot=True):\n",
    "    '''\n",
    "    少次数，但收集运行过程\n",
    "    '''\n",
    "    p_sim_all = []\n",
    "    # g_ind = g_indexes.copy()\n",
    "    # g_ind = \n",
    "    for i, g_id in enumerate(tqdm(g_inx_test, desc=\"Testing patterns\")):\n",
    "        _, _, p_sims, _ = attractor_test_optimized(\n",
    "            grid_org=pattern_average_activity[g_id], # 示例\n",
    "            p_org=p_all[i],   # 示例\n",
    "            Wgp_L=Wgp_L, Wgp_R=Wgp_R, W_pg=W_pg,\n",
    "            T_max=T_max, dt=dt, Nrun=Nrun,   # Nrun=500 现在是并行跑的\n",
    "            noise_stds=ls_noise\n",
    "        )\n",
    "        p_sim_all.append(p_sims)\n",
    "    p_sim_all = np.stack(p_sim_all)  # (Npatts, Nrun\n",
    "    p_sim_mean = np.mean(p_sim_all, axis=1)  # (Npatts, Nnoise)\n",
    "    p_sim_ste = np.std(p_sim_all, axis=1) / np.sqrt(p_sim_all.shape[1])  # (Npatts, Nnoise)\n",
    "    p_sim_mean.shape\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2,1,figsize=(8,5))\n",
    "        for i in range(p_sim_mean.shape[1]):\n",
    "            ax[0].errorbar(x_prefs, p_sim_mean[:,i], yerr=p_sim_ste[:,i], marker='o', label=f'noise {ls_noise[i]}')\n",
    "        ax[0].set_xlabel('Position Preference')\n",
    "        ax[0].set_ylabel('Mean Similarity')\n",
    "        ax[0].set_title('Mean Similarity vs Noise Level for Each Pattern')\n",
    "        ax[0].legend()\n",
    "        # plot trained grid_org\n",
    "        for i, g_id in enumerate(g_inx_train):\n",
    "            ax[1].plot(x_prefs, pattern_average_activity[g_id], label=f'Pattern {g_id}')\n",
    "        ax[1].set_xlabel('Position Preference')\n",
    "        ax[1].set_ylabel('Grid Cell Activity')\n",
    "        ax[1].set_title('Trained Grid Cell Patterns')\n",
    "        ax[1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return p_sim_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea15d43",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_org_all = batch_generate_place_patterns(pattern_average_activity, W_pg, T_s=5, dt=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ab664",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes = [5, 21]\n",
    "\n",
    "Wgp_L1, Wgp_L2 = train_place_grid_feedback(\n",
    "    pattern_average_activity, g_indexes, \n",
    "    N, Nh, dt, tau_s, tau_h,\n",
    "    W_LL, W_LR, W_RR, W_RL, \n",
    "    W_pg, gain_pg, Iext2, theta,\n",
    "    envelope, beta_0, e_mu, g_gp,\n",
    "    hebb_lr, \n",
    "    T_trail=0.1, n_runs=100, \n",
    "    return_activity=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03516850",
   "metadata": {},
   "source": [
    "#### 加噪声的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be64993",
   "metadata": {},
   "source": [
    "##### 动画可视化演化过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "784b4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_p_denoise_process_batch(Ng, p_org, Wgp_L, Wgp_R, W_pg, \n",
    "                      T_max=2, dt=0.01, noise_std=0, \n",
    "                      Nrun=5, sim_measure='Cosine', \n",
    "                      check_interval=50):\n",
    "    '''\n",
    "    向量化批处理版本的去噪过程，但是保存过程活动\n",
    "    '''\n",
    "    # 1. 维度推断与初始化\n",
    "    N_steps_test = int(T_max / dt)\n",
    "    N_grid = Ng\n",
    "    N_place = len(p_org)\n",
    "    \n",
    "    # 构建 Batch 初始状态\n",
    "    # Target pattern (N_place, 1) 用于广播计算相似度\n",
    "    p_target = p_org.reshape(-1, 1)\n",
    "    \n",
    "    # 批量生成噪声: (N_place, Batch_Size)\n",
    "    noise_matrix = np.random.normal(0, noise_std, (N_place, Nrun))\n",
    "    p_noise_batch = np.maximum(p_target + noise_matrix, 0)\n",
    "    p_test_batch = p_noise_batch.copy()   #每一时刻的p_test\n",
    "    p_test_batch_all = np.zeros((N_steps_test, N_place, Nrun))\n",
    "    # Grid 初始状态 (2*N_grid, Batch_Size)\n",
    "    # 假设 grid 初始为 0 (根据原代码)\n",
    "    s_test_batch = np.zeros((2 * N_grid, Nrun))\n",
    "    s_test_batch_all = np.zeros((N_steps_test, 2*N_grid, Nrun))\n",
    "    # 速度设为 0，标量即可，无需数组\n",
    "    v_val = 0.0 \n",
    "    \n",
    "    # 预计算常量，避免循环内重复索引\n",
    "    v_L = 1 - e_mu * v_val\n",
    "    v_R = 1 + e_mu * v_val\n",
    "    \n",
    "    # 广播 envelope beta_0: (N, 1)\n",
    "    # 假设 envelope 是 (N, 1) 或 (N,)，确保它是 (N, 1) 以便广播\n",
    "    env_b0 = (envelope * beta_0).reshape(-1, 1)\n",
    "\n",
    "    t = 0\n",
    "    sims = np.zeros(Nrun)\n",
    "    \n",
    "    # 2. 动力学循环\n",
    "    # 为了最大化 Batch 效率，通常不针对单个样本做 Early Stopping\n",
    "    # 而是当所有样本都收敛，或达到最大步数时退出。\n",
    "    # 这里为了速度，我们只在 check_interval 步数时检查。\n",
    "    \n",
    "    for t in range(N_steps_test):\n",
    "        # --- Grid Cell Dynamics ---\n",
    "        # Matrix Ops: (N, N) @ (N, Batch) -> (N, Batch)\n",
    "        p_test_batch_all[t,::] = p_test_batch\n",
    "        s_test_batch_all[t,::] = s_test_batch\n",
    "\n",
    "        g_LL = W_LL @ s_test_batch[:N]\n",
    "        g_LR = W_LR @ s_test_batch[N:]\n",
    "        g_RR = W_RR @ s_test_batch[N:]\n",
    "        g_RL = W_RL @ s_test_batch[:N]\n",
    "        \n",
    "        # Place -> Grid Input\n",
    "        # (N, N_p) @ (N_p, Batch) -> (N, Batch)\n",
    "        inp_gp_L = g_gp * (Wgp_L @ p_test_batch)\n",
    "        inp_gp_R = g_gp * (Wgp_R @ p_test_batch)\n",
    "        \n",
    "        # Total Grid Input\n",
    "        G_L = v_L * (g_LL + g_LR + env_b0) + inp_gp_L\n",
    "        G_R = v_R * (g_RR + g_RL + env_b0) + inp_gp_R\n",
    "        \n",
    "        G = np.vstack([G_L, G_R])\n",
    "        F = G * (G >= 0) # ReLU\n",
    "        \n",
    "        # Euler Integration\n",
    "        s_test_batch += (F * dt) - (s_test_batch * dt / tau_s)\n",
    "        \n",
    "        # --- Place Cell Dynamics ---\n",
    "        # Grid -> Place Input\n",
    "        hippo_drive = gain_pg * (W_pg @ s_test_batch) + Iext2\n",
    "        \n",
    "        phi_term = np.maximum(hippo_drive - theta, 0) # ReLU\n",
    "        \n",
    "        # Place Update\n",
    "        p_test_batch += (dt / tau_h) * (-p_test_batch + phi_term)\n",
    "        \n",
    "        # --- Efficiency Check ---\n",
    "        # 仅每隔 check_interval 步计算一次相似度\n",
    "        if t % check_interval == 0 and t > 0:\n",
    "            if sim_measure == 'Cosine':\n",
    "                # Vectorized Cosine Similarity\n",
    "                # p_test_batch: (M, B), p_target: (M, 1)\n",
    "                dot_prod = np.sum(p_test_batch * p_target, axis=0) # (B,)\n",
    "                norm_batch = np.linalg.norm(p_test_batch, axis=0)\n",
    "                norm_target = np.linalg.norm(p_target) # Scalar\n",
    "                \n",
    "                sims = dot_prod / (norm_batch * norm_target + 1e-9)\n",
    "            \n",
    "            # 如果这批数据里最差的一个都已经 > 0.99，则提前退出\n",
    "            if np.min(sims) > 0.999:\n",
    "                break\n",
    "\n",
    "    # # 3. Final Similarity Calculation\n",
    "    # if sim_measure == 'Cosine':\n",
    "    #     dot_prod = np.sum(p_test_batch * p_target, axis=0)\n",
    "    #     norm_batch = np.linalg.norm(p_test_batch, axis=0)\n",
    "    #     norm_target = np.linalg.norm(p_target)\n",
    "    #     sims = dot_prod / (norm_batch * norm_target + 1e-9)\n",
    "        \n",
    "    # # Grid denoised: average pooling\n",
    "    # # reshape to (2, N, Batch) then mean over axis 0 -> (N, Batch)\n",
    "    # g_denoised_batch = np.mean(s_test_batch.reshape(2, N_grid, -1), axis=0)\n",
    "    \n",
    "    return p_noise_batch, p_test_batch_all[:], s_test_batch_all[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b923546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置测试单个p_org，得到结果\n",
    "i = 10\n",
    "n_level = 0\n",
    "nrun = 5\n",
    "p_org_i = p_org_all[i]\n",
    "g_org_i = pattern_average_activity[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_n0, p_batch_all, s_batch_all = g_p_denoise_process_batch(N, p_org_i, Wgp_L1, Wgp_L2, W_pg, \n",
    "                      T_max=2, dt=0.01, noise_std=n_level, \n",
    "                      Nrun=nrun, sim_measure='Cosine', \n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "n = 3\n",
    "r_all = s_batch_all[:,:, n].copy().T\n",
    "r_place = p_batch_all[:,:, n].copy().T\n",
    "r_all.shape\n",
    "# Animation: mean grid activity (top) and place-cell heatmap (bottom)\n",
    "x_axis = np.asarray(x_prefs).squeeze()\n",
    "time_values = (\n",
    "    time_axis if 'time_axis' in globals() and len(time_axis) == r_all.shape[1]\n",
    "    else time_steps if 'time_steps' in globals() and len(time_steps) == r_all.shape[1]\n",
    "    else np.arange(r_all.shape[1]) * (dt if 'dt' in globals() else 1.0)\n",
    ")\n",
    "\n",
    "mean_init = r_all[:, 0].reshape(2,N,-1).mean(axis=0)\n",
    "place_init = r_place[:, 0]\n",
    "y_max_line = np.max(r_all[:, :]) * 1.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "18300e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_15912\\565777689.py:49: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc88ec3b06c4da783d021ec7e893954",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=1000.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib widget\n",
    "fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(10, 6), gridspec_kw={'height_ratios': [3, 1], 'hspace': 0.4})\n",
    "ax_top.plot(x_axis, g_org_i, color='tab:orange', lw=2, label='g_org for p_org')\n",
    "line_mean, = ax_top.plot(x_axis, mean_init, color='tab:blue', lw=2)\n",
    "ax_top.set_xlim(x_axis.min(), x_axis.max())\n",
    "ax_top.set_ylim(0, y_max_line if y_max_line > 0 else 1)\n",
    "ax_top.set_ylabel('Mean activity')\n",
    "ax_top.grid(True, alpha=0.3)\n",
    "\n",
    "im = ax_bottom.imshow(\n",
    "    place_init[None, :],\n",
    "    aspect='auto',\n",
    "    cmap='gray',\n",
    "    vmin=0,\n",
    "    vmax=max(place_init.max(), 1e-9),\n",
    "    extent=[0, Nh, 0, 1],\n",
    ")\n",
    "ax_bottom.set_yticks([])\n",
    "ax_bottom.set_xlabel('Place cell index')\n",
    "ax_bottom.set_title('Place-cell activity')\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax_bottom, orientation='horizontal', pad=0.3, fraction=0.15)\n",
    "cbar.set_label('Activity')\n",
    "\n",
    "def update(frame_idx):\n",
    "    left_activity = r_all[:N, frame_idx]\n",
    "    right_activity = r_all[N:, frame_idx]\n",
    "    mean_activity = (left_activity + right_activity) / 2\n",
    "    # mean_activity = r_all[:N, frame_idx]\n",
    "    line_mean.set_ydata(mean_activity)\n",
    "    ax_top.set_title(f'g_org{i}Mean grid activity (t={time_values[frame_idx]:.4f}s)')\n",
    "    \n",
    "    place_vec = r_place[:, frame_idx]\n",
    "    im.set_data(place_vec[None, :])\n",
    "    vmax = max(place_vec.max(), 1e-9)\n",
    "    im.set_clim(0, vmax)\n",
    "    cbar.update_normal(im)\n",
    "    return line_mean, im\n",
    "\n",
    "frame_step = max(1, r_all.shape[1] // 400)\n",
    "activity_anim = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(0, r_all.shape[1], frame_step),\n",
    "    interval=60,\n",
    "    blit=False,\n",
    "    repeat=True,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4e239630",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.event_source.stop()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eef58124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving animation to c:\\Users\\Windows11\\Nutstore\\1\\Reasoning\\VH-inspired-Reasoning-Model\\Place-Grid-Loop\\visualization\\20260212_19\\animations\\denoising_g32p3200_20260213_173051_gorg10_run3.gif...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "animation_dir = os.path.join(save_dir, 'animations')\n",
    "os.makedirs(animation_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = os.path.join(animation_dir, f'denoising_g{N}p{Nh}_{timestamp}_gorg{i}_run{n}.gif')\n",
    "\n",
    "# Save the animation as a GIF\n",
    "print(f\"Saving animation to {filename}...\")\n",
    "activity_anim.save(filename, writer='pillow', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f29ba",
   "metadata": {},
   "source": [
    "##### 统计-最后p的相似性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test last similarity of all patterns \n",
    "g_indexes_all = [i for i in range(len(pattern_average_activity))]\n",
    "ls_noise = [0,0.5,5,10]\n",
    "p_sim_all = plot_denoising_patterns(\n",
    "    pattern_average_activity, p_org_all, Wgp_L1, Wgp_L2, W_pg, g_indexes_all, g_indexes, x_prefs, ls_noise=ls_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d385ef",
   "metadata": {},
   "source": [
    "##### 统计：最后稳定的g的状态和测试状态的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_noise = [0,0.5,5,10]\n",
    "g_denoised_all = get_denoising_g_patterns(\n",
    "    pattern_average_activity, p_org_all, Wgp_L1, Wgp_L2, W_pg, g_indexes_all, ls_noise=ls_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Npatts, Nnoise,Ngrid, Nrun = g_denoised_all.shape\n",
    "global_mean = np.max(g_denoised_all.mean(axis=(0,1,3)))\n",
    "global_std = np.max(g_denoised_all.std(axis=(0,1,3)))\n",
    "\n",
    "\n",
    "for i, g_id in enumerate(g_indexes_all):\n",
    "    g_org = pattern_average_activity[g_id]\n",
    "    g_denoised_all_i = g_denoised_all[i,:,:,:]\n",
    "    fig, ax = plt.subplots(Nnoise,1, figsize=(5, 2*Nnoise))\n",
    "    for n in range(Nnoise):\n",
    "        # plot learned pattern\n",
    "        for g_l in g_indexes:\n",
    "            ax[n].plot(pattern_average_activity[g_l], lw=1, ls='dashed', color='red', label='g_trained')\n",
    "        g_n_all = g_denoised_all_i[n,:,:]\n",
    "        ax[n].plot(g_org, color='orange',lw=2, label='g_org')\n",
    "        mean_activity = g_n_all.mean(axis=1)\n",
    "        std_activity = g_n_all.std(axis=1)\n",
    "        ax[n].plot(mean_activity, color='steelblue', lw=1.5)\n",
    "        ax[n].fill_between(\n",
    "            np.arange(Ngrid),\n",
    "            mean_activity - std_activity,\n",
    "            mean_activity + std_activity,\n",
    "            color='steelblue',\n",
    "            alpha=0.2\n",
    "        )\n",
    "        ax[n].set_title(f'noise={ls_noise[n]}')\n",
    "        ax[n].grid(True, ls='dashed', alpha=0.5, color='grey')\n",
    "    # y_min = min(g_org.min(), g_denoised_all_i.min())\n",
    "    # y_max = max(g_org.max(), g_denoised_all_i.max())\n",
    "    # for axis in np.atleast_1d(ax):\n",
    "        ax[n].set_ylim(-0.5, np.round(global_mean+global_std, 1))\n",
    "        if n==0:\n",
    "            ax[n].legend(loc='upper right')\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fig_dir = os.path.join(save_dir, f'g{N}p{Nh}_attractor_test')\n",
    "    # plt.savefig(os.path.join(save_dir,f'g_denoised_{g_id}.png'),bbox_inches='tight',\n",
    "    #     pad_inches=0.1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c217976",
   "metadata": {},
   "source": [
    "###### animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.animation import FuncAnimation\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "%matplotlib widget\n",
    "# --- Animation Setup ---\n",
    "Npatts, Nnoise, Ngrid, Nrun = g_denoised_all.shape\n",
    "global_mean = np.max(g_denoised_all.mean(axis=(0, 1, 3)))\n",
    "global_std = np.max(g_denoised_all.std(axis=(0, 1, 3)))\n",
    "y_limit = (-0.5, np.round(global_mean + global_std, 1))\n",
    "\n",
    "# Initialize the figure and subplots for the animation\n",
    "fig, axes = plt.subplots(Nnoise, 1, figsize=(5, 2 * Nnoise))\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout for suptitle\n",
    "\n",
    "# --- Update Function for Animation ---\n",
    "def update(i):\n",
    "    \"\"\"Updates the plot for each frame (pattern).\"\"\"\n",
    "    # Clear previous frame's content\n",
    "    for ax in axes:\n",
    "        ax.clear()\n",
    "\n",
    "    g_id = g_indexes_all[i]\n",
    "    g_org = pattern_average_activity[g_id]\n",
    "    g_denoised_all_i = g_denoised_all[i]\n",
    "\n",
    "    for n in range(Nnoise):\n",
    "        ax = axes[n]\n",
    "        \n",
    "        # 1. Plot all trained patterns (dashed red lines)\n",
    "        for g_l in g_indexes:\n",
    "            ax.plot(pattern_average_activity[g_l], lw=1, ls='--', color='red', alpha=0.6)\n",
    "        \n",
    "        # 2. Plot the original pattern for this frame (orange)\n",
    "        ax.plot(g_org, color='orange', lw=2, label='Original Pattern')\n",
    "        \n",
    "        # 3. Plot the denoised mean and std deviation\n",
    "        g_n_all = g_denoised_all_i[n, :, :]\n",
    "        mean_activity = g_n_all.mean(axis=1)\n",
    "        std_activity = g_n_all.std(axis=1)\n",
    "        \n",
    "        ax.plot(mean_activity, color='steelblue', lw=1.5, label='Denoised Mean')\n",
    "        ax.fill_between(\n",
    "            np.arange(Ngrid),\n",
    "            mean_activity - std_activity,\n",
    "            mean_activity + std_activity,\n",
    "            color='steelblue',\n",
    "            alpha=0.2\n",
    "        )\n",
    "        \n",
    "        # 4. Set titles, limits, and legends\n",
    "        ax.set_title(f'Noise Std: {ls_noise[n]}')\n",
    "        ax.grid(True, ls='--', alpha=0.5, color='grey')\n",
    "        ax.set_ylim(y_limit)\n",
    "        \n",
    "        if n == 0:\n",
    "            # Create a custom legend to avoid duplicate labels\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            unique_labels = {\"Original Pattern\": handles[labels.index(\"Original Pattern\")],\n",
    "                             \"Denoised Mean\": handles[labels.index(\"Denoised Mean\")]}\n",
    "            # Add one entry for the trained patterns\n",
    "            unique_labels[\"Trained Patterns\"] = plt.Line2D([0], [0], color='red', lw=1, ls='--')\n",
    "            ax.legend(unique_labels.values(), unique_labels.keys(), loc='upper right')\n",
    "\n",
    "    fig.suptitle(f'Denoising Performance for Pattern Index: {g_id}')\n",
    "\n",
    "# --- Create and Save the Animation ---\n",
    "# Create the animation object\n",
    "ani = FuncAnimation(fig, update, frames=len(g_indexes_all), blit=False, interval=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae00f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ani.event_source.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87188298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define save directory and filename\n",
    "# Ensure `save_dir` is defined from a previous cell\n",
    "animation_dir = os.path.join(save_dir, 'animations')\n",
    "os.makedirs(animation_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = os.path.join(animation_dir, f'denoised_patterns_g{N}p{Nh}_{timestamp}.gif')\n",
    "\n",
    "# Save the animation as a GIF\n",
    "print(f\"Saving animation to {filename}...\")\n",
    "ani.save(filename, writer='pillow', fps=2)\n",
    "print(\"Animation saved successfully.\")\n",
    "\n",
    "# Close the plot to prevent it from displaying statically in the notebook\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d49deab",
   "metadata": {},
   "source": [
    "## Factors of Multi-Pattern Attractor\n",
    "+ 什么因素影响多模式学习后形成的吸引子？\n",
    "    + 学习的模式组合本身\n",
    "    + 学习的模式组合的顺序\n",
    "+ 什么因素导致多模式学习无法成功？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71c6ef",
   "metadata": {},
   "source": [
    "### 模式组合不变，改变学习顺序，查看学习结果\n",
    "1. 改变模式学习的顺序进行训练  \n",
    "    保存**每次训练的权重矩阵历史**，最后循环读取并画图，查看不同训练次序下的权重矩阵是否有大的差异\n",
    "2. 吸引子测试阶段（保存每次的权重矩阵，读取最后一个权重），进行吸引子分析，看对于学习的所有的g_patts，是否不同的权重矩阵收敛到的吸引子不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4066a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_average_activity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes_diff = np.array([np.random.permutation(32)[:5] for _ in range(9)])\n",
    "print(g_indexes_diff)\n",
    "g_indexes_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45be8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes_all = np.repeat(g_indexes, 3, axis=0)\n",
    "g_indexes_all = np.tile(g_indexes, (len(g_indexes), 1))\n",
    "for i in range(len(g_indexes)):\n",
    "    g_indexes_all[i,:] = np.roll(g_indexes_all[i,:], shift=i)\n",
    "print(g_indexes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Wgp(pattern_average_activity,g_indexes,history_dir, T_trial=0.1, n_runs=100, save_text=''):\n",
    "\n",
    "    '''训练位置细胞到网格细胞的连接权重矩阵W_gp\n",
    "    保存权重矩阵的变化历史到training_history文件夹下\n",
    "    输出: 训练后的Wgp_L, Wgp_R\n",
    "    ----------\n",
    "    pattern_average_activity: 网格细胞活动模式集 (Npatts, N)\n",
    "    g_indexes: 训练使用的模式索引列表\n",
    "    T_trial: 每个trial的时间长度(s)\n",
    "    n_runs: 重复训练次数\n",
    "    ----------'''\n",
    "    # training save weight matrices\n",
    "    n_steps = int(T_trial/dt)\n",
    "    # initialize Wgp_L and Wgp_R\n",
    "    # Wgp_L = np.random.rand(N, Nh) * 0.1\n",
    "    Wgp_L = np.zeros((N, Nh))\n",
    "    # Wgp_R = np.random.rand(N, Nh) * 0.1\n",
    "    Wgp_R = np.zeros((N, Nh))\n",
    "    if len(save_text) > 0:\n",
    "        # normalize weights\n",
    "        timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "        \n",
    "        os.makedirs(history_dir, exist_ok=True)\n",
    "        total_steps = n_runs * len(g_indexes) * n_steps\n",
    "        wgp_L_path = os.path.join(history_dir, f\"Wgp_L_history_{timestamp}_{save_text}.dat\")\n",
    "        wgp_R_path = os.path.join(history_dir, f\"Wgp_R_history_{timestamp}_{save_text}.dat\")\n",
    "        Wgp_L_history = np.memmap(wgp_L_path, dtype=np.float32, mode='w+', shape=(total_steps, N, Nh))\n",
    "        Wgp_R_history = np.memmap(wgp_R_path, dtype=np.float32, mode='w+', shape=(total_steps, N, Nh))\n",
    "\n",
    "    v = np.zeros(n_runs*n_steps*len(g_indexes))   # 速度输入为0\n",
    "    # record population spikes\n",
    "    r_all = np.zeros((2*N, n_runs*n_steps*len(g_indexes)))\n",
    "    r_place = np.zeros((Nh, n_runs*n_steps*len(g_indexes)))\n",
    "    p_prev = np.zeros((Nh, 1)) \n",
    "    t_all = 0\n",
    "    for run in range(n_runs):\n",
    "        for g_idx in g_indexes:\n",
    "            # 每个trial顺序学习Npatts个模式\n",
    "            g = pattern_average_activity[g_idx].reshape(-1,1)  # (N,1)\n",
    "            s_prev = np.vstack([g,g])   # initialize with previous g\n",
    "            spk = 0   # np.zeros((2*N, n_steps))  # Total spiking\n",
    "            for t_s in range(n_steps):\n",
    "                # Hippocampal (place-cell) dynamics\n",
    "                hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "                phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "                p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "                r_place[:, t_all:t_all + 1] = p_new\n",
    "                \n",
    "                # two population of neurons\n",
    "                # left population\n",
    "                v_L = (1-e_mu * v[t_all])\n",
    "                g_LL = W_LL @ s_prev[:N]\n",
    "                g_LR = W_LR @ s_prev[N:]\n",
    "                G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "                # RIGHT population\n",
    "                v_R = (1 + e_mu * v[t_all])\n",
    "                g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "                g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "                G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "\n",
    "                G = np.vstack([G_L, G_R])\n",
    "                    \n",
    "                # Linear transfer function (ReLU) + Poisson Spike\n",
    "                F = G * (G >= 0)  # ReLU activation\n",
    "                spk = F * dt  # 确定性形式\n",
    "                # Update population activity\n",
    "                s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "                r_all[:, t_all:t_all + 1] = s_new\n",
    "\n",
    "                # Hebbian update for place -> grid synapses\n",
    "                hebb_L = np.outer(s_prev[:N].flatten(), p_new.flatten())\n",
    "                hebb_R = np.outer(s_prev[N:].flatten(), p_new.flatten())\n",
    "                # break\n",
    "                Wgp_L += hebb_lr * hebb_L\n",
    "                Wgp_R += hebb_lr * hebb_R\n",
    "                norms_L = np.linalg.norm(Wgp_L, axis=0, keepdims=True)   # axis = 1 对于每一行单独计算，即网格细胞输入归一化 \n",
    "                norms_R = np.linalg.norm(Wgp_R, axis=0, keepdims=True)    # axis = 0 对于每一列单独计算, 位置细胞归一化.每个位置细胞的输出相同\n",
    "                norms_L[norms_L == 0] = 1.0    # 避免除0问题\n",
    "                norms_R[norms_R == 0] = 1.0 \n",
    "                Wgp_L = Wgp_L / norms_L\n",
    "                Wgp_R = Wgp_R / norms_R\n",
    "\n",
    "                # Save weight matrices at each time step\n",
    "                Wgp_L_history[t_all] = Wgp_L.astype(np.float32)\n",
    "                Wgp_R_history[t_all] = Wgp_R.astype(np.float32)\n",
    "\n",
    "                s_prev = s_new\n",
    "                p_prev = p_new\n",
    "                t_all += 1\n",
    "    if len(save_text) > 0:\n",
    "        Wgp_L_history.flush()\n",
    "        Wgp_R_history.flush()\n",
    "        del Wgp_L_history, Wgp_R_history\n",
    "    return Wgp_L, Wgp_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dir = os.path.join(os.getcwd(), \"training_history\")\n",
    "W_gp_L = []\n",
    "W_gp_R = []\n",
    "for g_com in range(g_indexes_diff.shape[0]):\n",
    "    g_indexes = g_indexes_diff[g_com,:].tolist()\n",
    "    save_text = f'diff_{g_com}'\n",
    "    Wgp_L_c, Wgp_R_c = train_Wgp(pattern_average_activity, g_indexes, history_dir, T_trial=0.1, n_runs=100, save_text=save_text)\n",
    "    W_gp_L.append(Wgp_L_c)\n",
    "    W_gp_R.append(Wgp_R_c)\n",
    "W_gp_L = np.stack(W_gp_L)  # (Ncombi, N, Nh)\n",
    "W_gp_R = np.stack(W_gp_R)  # (Ncombi, N, Nh)\n",
    "W_gp_L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1521a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化W_gp\n",
    "def visualization_Wgp(Wgp_L, Wgp_R, save_text='', folder = ''):\n",
    "    fig, (ax_L, ax_R) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot Wgp_L\n",
    "    im_L = ax_L.imshow(Wgp_L, aspect='auto', cmap='viridis')\n",
    "    ax_L.set_xlabel('Place cell index')\n",
    "    ax_L.set_ylabel('Grid cell index (Left)')\n",
    "    ax_L.set_title(f'{save_text}_Wgp_L (sum={Wgp_L.sum():.2f})')\n",
    "    cbar_L = plt.colorbar(im_L, ax=ax_L, orientation='vertical', pad=0.02, fraction=0.046)\n",
    "\n",
    "    # Plot Wgp_R\n",
    "    im_R = ax_R.imshow(Wgp_R, aspect='auto', cmap='viridis')\n",
    "    ax_R.set_xlabel('Place cell index')\n",
    "    ax_R.set_ylabel('Grid cell index (Right)')\n",
    "    ax_R.set_title(f'{save_text}_Wgp_R (sum={Wgp_R.sum():.2f})')\n",
    "    cbar_R = plt.colorbar(im_R, ax=ax_R, orientation='vertical', pad=0.02, fraction=0.046)\n",
    "\n",
    "    # Set global colorbar limits\n",
    "    vmax_global = max(Wgp_L.max(), Wgp_R.max())\n",
    "    vmin_global = min(Wgp_L.min(), Wgp_R.min())\n",
    "    im_L.set_clim(vmin_global, vmax_global)\n",
    "    im_R.set_clim(vmin_global, vmax_global)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if folder != '':\n",
    "        os.makedirs(os.path.join(folder,'figures'), exist_ok=True)\n",
    "        fig.savefig(os.path.join(folder,'figures', f'{save_text}_Wgp.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = r\"D:\\\\prob_learning\\\\grid_cell\\\\202601_Loop model\\\\visualization\"\n",
    "for g_com in range(W_gp_L.shape[0]):\n",
    "    save_text = f'diff_{g_com}'\n",
    "    visualization_Wgp(W_gp_L[g_com], W_gp_R[g_com], save_text=save_text, folder=save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf20a51",
   "metadata": {},
   "source": [
    "可视化不同的模式学习结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a052817",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncom, Ng_p = g_indexes_diff.shape\n",
    "ls_noise = [0,2,4,8,10,20,40]\n",
    "T_max = 1.5\n",
    "dt = 0.0005\n",
    "p_sim_com_all = []\n",
    "g_denoised_com_all = []\n",
    "for n in range(Ncom):\n",
    " \n",
    "    g_idxed = g_indexes_diff[n,:].tolist()\n",
    "    Wgp_L = W_gp_L[n]\n",
    "    Wgp_R = W_gp_R[n]\n",
    "\n",
    "    p_sim_all = []\n",
    "    g_denoised_all = []\n",
    "    for i,g_id in enumerate(g_idxed):\n",
    "        grid_org = pattern_average_activity[g_id]\n",
    "        p_org = p_tests[i]\n",
    "        # normalize grid_org\n",
    "        p_noise, p_denoised, p_sim, g_denoise = attractor_test2(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = T_max, dt = dt,\n",
    "                                Nrun = 100,noise_stds = ls_noise, sim_measure = 'Cosine')\n",
    "        p_sim_all.append(p_sim)\n",
    "        g_denoised_all.append(g_denoise)\n",
    "    p_sim_com_all.append(p_sim_all)\n",
    "    g_denoised_com_all.append(g_denoised_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1907a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exoprt results\n",
    "export_dir = os.path.join(save_folder, 'exports')\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'p_sim_com_all.npy'),\n",
    "    np.array(p_sim_com_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'g_denoised_com_all.npy'),\n",
    "    np.array(g_denoised_com_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7481ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 所有模式组合的学习结果\n",
    "for n in range(Ncom):\n",
    "    g_idxed = g_indexes_diff[n,:].tolist()\n",
    "    p_sim_all = p_sim_com_all[n]\n",
    "    g_denoised_all = g_denoised_com_all[n]\n",
    "    fig, axs = plt.subplots(2,1, figsize=(6, 4), sharex=True)\n",
    "    # 设计一个颜色映射\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(g_idxed)))\n",
    "    g_global_max = np.array(g_denoised_all).max()\n",
    "    g_global_min = np.array(g_denoised_all).min()\n",
    "    for i,g_id in enumerate(g_idxed):\n",
    "        grid_org = pattern_average_activity[g_id]\n",
    "        p_org = p_tests[i]\n",
    "        p_sim = p_sim_all[i]\n",
    "        g_denoise = g_denoised_all[i]\n",
    "         # Plotting\n",
    "        axs[0].plot(np.arange(N), grid_org,color=colors[i], linewidth=2, label=str(g_id))\n",
    "        axs[1].plot(np.arange(N), g_denoise, color=colors[i], linestyle='--', linewidth=2, label=str(g_id))\n",
    "        axs[0].set_title(f'Original Grid pattern (g_idx={g_id})')\n",
    "        axs[1].legend(bbox_to_anchor = (1.15,0.95), loc='upper right', fontsize='small')\n",
    "        axs[1].set_xlim(0, N - 1)\n",
    "        axs[1].set_ylim(g_global_min, g_global_max * 1.05)\n",
    "        axs[1].set_title(f'Learned Grid pattern (g_idx={g_id})')\n",
    "        axs[1].set_xlabel('Neuron index')\n",
    "        axs[1].set_ylabel('Activity')\n",
    "    fig.savefig(\n",
    "        os.path.join(save_folder, 'figures', f'combi_{n}th_all_learned_patterns.png'),\n",
    "        bbox_inches='tight',\n",
    "        pad_inches=0.1\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization 所有的模式的学习结果\n",
    "for n in range(Ncom):\n",
    "    g_indexes = g_indexes_diff[n,:].tolist()\n",
    "\n",
    "    grid_global_min = 0.0\n",
    "    grid_global_max = pattern_average_activity[g_indexes, :].max()\n",
    "    place_global_max = p_tests[:len(g_indexes), :].max()\n",
    "    time_axis = np.arange(int(T_max / dt)) * dt\n",
    "    for i,g_id in enumerate(g_indexes):\n",
    "        grid_org = pattern_average_activity[g_id]\n",
    "        p_org = p_tests[i]\n",
    "        p_sim = p_sim_com_all[n][i]\n",
    "        g_denoise = g_denoised_com_all[n][i]\n",
    "        # Plotting\n",
    "        fig = plt.figure(figsize=(13.5, 5))\n",
    "        gs = fig.add_gridspec(2, 2, width_ratios=[1, 2], height_ratios=[1, 1],\n",
    "                            wspace=0.3, hspace=0.55)\n",
    "        ax_grid = fig.add_subplot(gs[0, 0])\n",
    "        ax_place = fig.add_subplot(gs[1, 0])\n",
    "        ax_sim = fig.add_subplot(gs[:, 1])\n",
    "\n",
    "        ax_grid.plot(np.arange(N), grid_org, color='steelblue', linewidth=2, label='Original\\n Grid')\n",
    "        ax_grid.plot(np.arange(N), g_denoise, color='orange', linestyle='--', linewidth=2, label='Denoised\\n Grid')\n",
    "        ax_grid.legend(bbox_to_anchor = (1.35,0.95), loc='upper right', fontsize='small')\n",
    "        ax_grid.set_xlim(0, N - 1)\n",
    "        ax_grid.set_ylim(grid_global_min, grid_global_max * 1.05)\n",
    "        ax_grid.set_title(f'Grid-Com_{n} Grid pattern (g_idx={g_id})')\n",
    "        ax_grid.set_xlabel('Neuron index')\n",
    "        ax_grid.set_ylabel('Activity')\n",
    "\n",
    "        im = ax_place.imshow(\n",
    "            p_org[None, :],\n",
    "            aspect='auto',\n",
    "            cmap='gray',\n",
    "            vmin=0.0,\n",
    "            vmax=place_global_max * 1.05,\n",
    "            extent=[0, Nh, 0, 1],\n",
    "        )\n",
    "        ax_place.set_title(f'Place pattern (g_idx={g_id})', pad=12)\n",
    "        ax_place.set_xlabel('Place cell index')\n",
    "        ax_place.set_yticks([])\n",
    "        plt.colorbar(im, ax=ax_place, orientation='horizontal', pad=0.35, fraction=0.2, label='Activity')\n",
    "\n",
    "        ax_sim.set_title(f'Attractor Test for Archetype {g_id}')\n",
    "        ax_sim.set_xlabel('Time (s)')\n",
    "        ax_sim.set_ylabel('Similarity')\n",
    "        ax_sim.set_ylim(0, 1.1)\n",
    "        ax_sim.grid(True, color='grey', ls='dashed', lw=1, alpha=0.3)\n",
    "\n",
    "        for noise_idx, noise_std in enumerate(ls_noise):\n",
    "            mean_sim = np.mean(p_sim[:, noise_idx, :], axis=0)\n",
    "            std_sim = np.std(p_sim[:, noise_idx, :], axis=0)\n",
    "            ax_sim.fill_between(time_axis, mean_sim - std_sim, mean_sim + std_sim, alpha=0.15)\n",
    "            ax_sim.plot(time_axis, mean_sim, label=f'STD={noise_std}', linewidth=2)\n",
    "\n",
    "        ax_sim.legend(loc='lower right', fontsize='small')\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.join(save_folder,'figures',f'combi_{n}'), exist_ok=True)\n",
    "        fig.savefig(\n",
    "        os.path.join(save_folder, 'figures', f'combi_{n}', f'combi_{n}_{g_id}.png'),\n",
    "        bbox_inches='tight',\n",
    "        pad_inches=0.1\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab332b09",
   "metadata": {},
   "source": [
    "## Check all Attractors in the trained System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e3ffa",
   "metadata": {},
   "source": [
    "对于训练后的网络，系统性分析网络所有的模式是否为吸引子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果不学习Wgp\n",
    "Wgp_L_pre = np.random.rand(N, Nh) * 0.1\n",
    "Wgp_R_pre = np.random.rand(N, Nh) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be95262",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成稳定的pattern的place cell活动\n",
    "# g_idxed = [i for i in range(pattern_average_activity.shape[0])]\n",
    "g_idxed = [0,12,24]\n",
    "p_tests = []\n",
    "T_s = 5   # 保证收敛\n",
    "dt = 0.0005\n",
    "for g_id in g_idxed:\n",
    "    grid_org = pattern_average_activity[g_id].reshape(-1,1)\n",
    "    s_new = np.vstack([grid_org, grid_org])   # initialize with previous g\n",
    "    # print(s_new.shape)\n",
    "    p_hist = np.zeros((Nh,n_steps_test))\n",
    "    p_test = np.zeros((Nh, )) \n",
    "    n_steps_test = int(T_s/dt)\n",
    "    # p_hist = np.zeros((Nh,n_steps_test))\n",
    "    for t in range(n_steps_test):\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        p_hist[:,t] = p_test\n",
    "    # print(p_test.shape)\n",
    "    p_tests.append(p_test)\n",
    "p_tests = np.stack(p_tests)  # (Npatts, Nh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "grid_org = pattern_average_activity[g_idxed[i]]\n",
    "place_pattern = p_tests[i]\n",
    "\n",
    "fig, (ax_grid, ax_place) = plt.subplots(2, 1, figsize=(8, 5), height_ratios=[2, 1], constrained_layout=True)\n",
    "\n",
    "ax_grid.plot(np.arange(grid_org.size), grid_org, color='steelblue', linewidth=2)\n",
    "ax_grid.set_title(f'Grid Pattern (index={idx})')\n",
    "ax_grid.set_xlabel('Neuron index')\n",
    "ax_grid.set_ylabel('Activity')\n",
    "ax_grid.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "im = ax_place.imshow(place_pattern[None, :], aspect='auto', cmap='gray',\n",
    "                     extent=[0, place_pattern.size, 0, 1],\n",
    "                     vmin=0.0, vmax=max(place_pattern.max(), 1e-9))\n",
    "ax_place.set_title(f'Place Pattern (index={idx})')\n",
    "ax_place.set_xlabel('Place cell index')\n",
    "ax_place.set_yticks([])\n",
    "plt.colorbar(im, ax=ax_place, orientation='horizontal', pad=0.3, fraction=0.2, label='Activity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5642e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10,4))\n",
    "# 只打印最后一个pattern的place cell活动随时间变化\n",
    "plt.plot(np.mean(p_hist, axis=0))\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mean Place Cell Activity')  \n",
    "plt.title('Place Cell Activity Over Time for Archetype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ed6b5",
   "metadata": {},
   "source": [
    "设定p和g的初始状态并run动画观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bece933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# p_start = np.zeros((Nh,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a38fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_p_g_loop(grid_start,p_start, Wgp_L, Wgp_R, T = 10):\n",
    "        # Fiete,2009 with hippocampal feedback\n",
    "    n_steps = int(T/dt)\n",
    "    v = np.zeros(n_steps)   # 速度输入为0\n",
    "    # record population spikes\n",
    "    r_all = np.zeros((2*N, n_steps))\n",
    "    r_place = np.zeros((Nh, n_steps))\n",
    "    # p_prev = np.zeros((Nh, 1)) \n",
    "\n",
    "    # add noise to place\n",
    "    p_prev = p_start.copy()\n",
    "    # noise_std = 0.0\n",
    "    # p_prev = p_prev + np.random.normal(0,noise_std, p_prev.shape)\n",
    "    # p_prev = np.maximum(p_prev, 0).reshape(-1,1)  # ensure non-negative\n",
    "\n",
    "    # initialize grid activity\n",
    "    s_prev = np.vstack([grid_start, grid_start])   # initialize with previous \n",
    "    # s_prev = np.zeros((2*N,1))\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        # Hippocampal (place-cell) dynamics\n",
    "        hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "        p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "        r_place[:, t:t + 1] = p_new\n",
    "        \n",
    "        # two population of grid neurons\n",
    "        # left population\n",
    "        v_L = (1-e_mu * v[t])\n",
    "        g_LL = W_LL @ s_prev[:N]\n",
    "        g_LR = W_LR @ s_prev[N:]\n",
    "        G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "        # RIGHT population\n",
    "        v_R = (1 + e_mu * v[t])\n",
    "        g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "        g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "        G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "        G = np.vstack([G_L, G_R])\n",
    "            \n",
    "        # Linear transfer function (ReLU) + Poisson Spike\n",
    "        F = G * (G >= 0)  # ReLU activation\n",
    "        spk = F * dt  # 确定性形式\n",
    "        # Update population activity\n",
    "        s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "        r_all[:, t:t + 1] = s_new\n",
    "        s_prev = s_new\n",
    "        p_prev = p_new\n",
    "    return r_all, r_place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51af9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_start = np.zeros_like(grid_org).reshape(-1,1)\n",
    "# grid_start = grid_org.reshape(-1,1)\n",
    "p_start = p_tests[i].reshape(-1,1)\n",
    "r_all_untrain, r_place_untrain = run_p_g_loop(grid_start, p_start, Wgp_L, Wgp_R, T=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdac719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiete,2009 with hippocampal feedback\n",
    "# 非函数版本\n",
    "T = 10\n",
    "n_steps = int(T/dt)\n",
    "v = np.zeros(n_steps)   # 速度输入为0\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "r_place = np.zeros((Nh, n_steps))\n",
    "# p_prev = np.zeros((Nh, 1)) \n",
    "\n",
    "# add noise to place\n",
    "p_prev = p_start.copy()\n",
    "# noise_std = 0.0\n",
    "# p_prev = p_prev + np.random.normal(0,noise_std, p_prev.shape)\n",
    "# p_prev = np.maximum(p_prev, 0).reshape(-1,1)  # ensure non-negative\n",
    "\n",
    "# initialize grid activity\n",
    "# s_prev = np.vstack([grid_start, grid_start])   # initialize with previous \n",
    "s_prev = np.zeros((2*N,1))\n",
    "\n",
    "for t in range(n_steps):\n",
    "    # Hippocampal (place-cell) dynamics\n",
    "    hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "    phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "    p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "    r_place[:, t:t + 1] = p_new\n",
    "    \n",
    "    # two population of grid neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "    spk = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "    r_all[:, t:t + 1] = s_new\n",
    "    s_prev = s_new\n",
    "    p_prev = p_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiete,2009 with hippocampal feedback\n",
    "# 非函数版本\n",
    "T = 10\n",
    "n_steps = int(T/dt)\n",
    "v = np.zeros(n_steps)   # 速度输入为0\n",
    "# record population spikes\n",
    "r_all = np.zeros((2*N, n_steps))\n",
    "r_place = np.zeros((Nh, n_steps))\n",
    "# p_prev = np.zeros((Nh, 1)) \n",
    "\n",
    "# add noise to place\n",
    "p_prev = p_start.copy()\n",
    "# noise_std = 0.0\n",
    "# p_prev = p_prev + np.random.normal(0,noise_std, p_prev.shape)\n",
    "# p_prev = np.maximum(p_prev, 0).reshape(-1,1)  # ensure non-negative\n",
    "\n",
    "# initialize grid activity\n",
    "# s_prev = np.vstack([grid_start, grid_start])   # initialize with previous \n",
    "s_prev = np.zeros((2*N,1))\n",
    "\n",
    "for t in range(n_steps):\n",
    "    # Hippocampal (place-cell) dynamics\n",
    "    hippo_drive = gain_pg * W_pg @ s_prev + Iext2    # grid -> place input\n",
    "    phi_term = relu(hippo_drive - theta).reshape(-1,1)\n",
    "    p_new = p_prev + dt / tau_h * (-p_prev + phi_term)\n",
    "    r_place[:, t:t + 1] = p_new\n",
    "    \n",
    "    # two population of grid neurons\n",
    "    # left population\n",
    "    v_L = (1-e_mu * v[t])\n",
    "    g_LL = W_LL @ s_prev[:N]\n",
    "    g_LR = W_LR @ s_prev[N:]\n",
    "    G_L = v_L * ((g_LL + g_LR) + envelope * beta_0) + g_gp * Wgp_L @ p_new\n",
    "    # RIGHT population\n",
    "    v_R = (1 + e_mu * v[t])\n",
    "    g_RR = W_RR @ s_prev[N:]  # R->R\n",
    "    g_RL = W_RL @ s_prev[:N]  # L->R\n",
    "    G_R = v_R * ((g_RR + g_RL) + envelope * beta_0) + g_gp * Wgp_R @ p_new\n",
    "    G = np.vstack([G_L, G_R])\n",
    "        \n",
    "    # Linear transfer function (ReLU) + Poisson Spike\n",
    "    F = G * (G >= 0)  # ReLU activation\n",
    "    spk = F * dt  # 确定性形式\n",
    "    # Update population activity\n",
    "    s_new = s_prev + spk - s_prev * dt / tau_s\n",
    "    r_all[:, t:t + 1] = s_new\n",
    "    s_prev = s_new\n",
    "    p_prev = p_new\n",
    "\n",
    "# 动画部分被搬走了\n",
    "# ani.event_source.stop()\n",
    "# %matplotlib inline\n",
    "\n",
    "# print(\"Saving animation...\")\n",
    "# folder = 'visualization'\n",
    "# cur_dir = os.getcwd()\n",
    "# folder_path = os.path.join(cur_dir, folder)\n",
    "# print(folder_path)\n",
    "# if not os.path.exists(folder_path):\n",
    "#     print(f'文件夹{folder}生成')\n",
    "#     os.makedirs(folder_path)\n",
    "# timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "# # ani.save('neural_sheet_activity'+timestamp+'.mp4', writer='ffmpeg', fps=20, dpi=100)\n",
    "# path = r'D:\\\\prob_learning\\\\grid_cell\\\\202601_Loop model\\\\visualization\\\\exports\\\\pg_Mul-1D_denoise_32_0206'\n",
    "# ani.save(os.path.join(path, f'p3200-grid32_1M1D_ginit-rand{g_idxed[i]}trained_noise0'+timestamp+'.gif'), writer='pillow', fps=20, dpi=100)\n",
    "# print(\"Animation saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3d71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化每个 g-p 模式的去噪效果（包含去噪前后 place pattern）\n",
    "denoise_fig_dir = os.path.join(folder_path, '020510', 'gp_denoise_inspection')\n",
    "os.makedirs(denoise_fig_dir, exist_ok=True)\n",
    "grid_axis = np.arange(N)\n",
    "for idx, g_id in enumerate(g_idxed):\n",
    "    grid_org = np.asarray(pattern_average_activity[g_id], dtype=float).reshape(-1)\n",
    "    grid_denoise = np.asarray(g_denoised_all[idx], dtype=float).reshape(-1)\n",
    "    place_clean = np.asarray(p_tests[idx], dtype=float).reshape(-1)\n",
    "    place_noisy = np.asarray(p_noise_all[idx], dtype=float).reshape(-1)\n",
    "    place_denoised = np.asarray(p_denoised_all[idx], dtype=float).reshape(-1)\n",
    "    vmax_place = float(max(np.max(place_clean), np.max(place_noisy), np.max(place_denoised), 1e-6))\n",
    "    grid_min = float(np.min([grid_org.min(), grid_denoise.min()]))\n",
    "    grid_max = float(np.max([grid_org.max(), grid_denoise.max()]))\n",
    "    grid_range = max(grid_max - grid_min, 1e-6)\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    gs = fig.add_gridspec(3, 2, width_ratios=[2, 3], height_ratios=[1, 1, 1], wspace=0.05, hspace=0.15)\n",
    "    ax_line = fig.add_subplot(gs[:, 0])\n",
    "    ax_line.plot(grid_axis, grid_org, color='steelblue', linewidth=2, label='grid_org')\n",
    "    ax_line.plot(grid_axis, grid_denoise, color='darkorange', linestyle='--', linewidth=2, label='grid_denoise')\n",
    "    ax_line.set_xlim(0, N - 1)\n",
    "    ax_line.set_ylim(grid_min - 0.05 * grid_range, grid_max + 0.05 * grid_range)\n",
    "    ax_line.set_xlabel('Grid cell index')\n",
    "    ax_line.set_ylabel('Activity')\n",
    "    ax_line.set_title(f'g-p denoise comparison | g_idx={g_id}')\n",
    "    ax_line.legend(loc='upper right', fontsize='small')\n",
    "    heatmap_data = [\n",
    "        ('p_test (clean)', place_clean),\n",
    "        ('p_noisy', place_noisy),\n",
    "        ('p_denoised', place_denoised),\n",
    "    ]\n",
    "    for row, (title, data) in enumerate(heatmap_data):\n",
    "        ax_heat = fig.add_subplot(gs[row, 1])\n",
    "        heatmap_array = np.asarray(data, dtype=float)[None, :]\n",
    "        ax_heat.imshow(heatmap_array, aspect='auto', cmap='gray', vmin=0.0, vmax=vmax_place, extent=[0, Nh, 0, 1])\n",
    "        ax_heat.set_title(title, fontsize=9, pad=4)\n",
    "        ax_heat.set_yticks([])\n",
    "        if row < len(heatmap_data) - 1:\n",
    "            ax_heat.set_xticks([])\n",
    "        else:\n",
    "            ax_heat.set_xlabel('Place cell index')\n",
    "        for spine in ax_heat.spines.values():\n",
    "            spine.set_visible(False)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.suptitle(f'g_id {g_id} denoising', y=0.995, fontsize=12)\n",
    "    out_path = os.path.join(denoise_fig_dir, f'g_idx_{g_id:04d}_denoise.png')\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9235fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attractor_test1(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, Nrun = 100,noise_stds = [2], sim_measure = 'Cosine'):\n",
    "    \n",
    "    '''验证多个噪声强度下网络的去噪能力\n",
    "    input: single pattern grid_org, p_org\n",
    "    output: p_noise, p_denoised, p_sim, g_denoised'''\n",
    "    Nn = len(noise_stds)\n",
    "    # n_steps_test = int(T_max / dt)\n",
    "    p_sim = np.zeros((Nrun, Nn))  # collect p similarity over time_steps\n",
    "    for n in range(Nn):\n",
    "        noise_std = noise_stds[n]\n",
    "        for r in range(Nrun):\n",
    "            p_noise, p_denoised, sim, g_denoised = g_p_denoise(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max, dt, noise_std, sim_measure)\n",
    "            p_sim[r, n] = sim\n",
    "    # 返回的p_sim shape = (Nrun, Nn)，每一行对应一个trial的不同噪声强度下的sim值\n",
    "    return p_noise, p_denoised, p_sim, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697eeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_noise = [0.001, 0.1, 0.5,2, 4]\n",
    "ls_noise = [0.1]\n",
    "T_max = 1.5\n",
    "dt = 0.0005\n",
    "\n",
    "grid_global_min = 0.0\n",
    "grid_global_max = pattern_average_activity[g_idxed, :].max()\n",
    "place_global_max = p_tests[:len(g_idxed), :].max()\n",
    "time_axis = np.arange(int(T_max / dt)) * dt\n",
    "\n",
    "p_sim_all = []\n",
    "g_denoised_all = []\n",
    "p_denoised_all = []\n",
    "p_noise_all = []\n",
    "for i,g_id in enumerate(g_idxed):\n",
    "    grid_org = pattern_average_activity[g_id]\n",
    "    p_org = p_tests[i]\n",
    "    # normalize grid_org\n",
    "    p_noise, p_denoised, p_sim, g_denoise = attractor_test1(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = T_max, dt = dt,\n",
    "                            Nrun = 100,noise_stds = ls_noise, sim_measure = 'Cosine')\n",
    "    p_sim_all.append(p_sim)\n",
    "    g_denoised_all.append(g_denoise)\n",
    "    p_denoised_all.append(p_denoised)\n",
    "    p_noise_all.append(p_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18839615",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_all = np.array(p_sim_all, dtype=object)  # (Npatts, Nrun, Nn)\n",
    "g_denoised_all = np.array(g_denoised_all, dtype=object)\n",
    "p_denoised_all = np.array(p_denoised_all, dtype=object)\n",
    "p_noise_all = np.array(p_noise_all, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a376e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r'D:\\\\prob_learning\\\\grid_cell\\\\202601_Loop model\\\\visualization\\\\exports\\\\pg_Mul-1D_denoise_32_0205_143446'\n",
    "\n",
    "np.save(os.path.join(save_dir, 'p_sim_all_n3.npy'), p_sim_all, allow_pickle=True)\n",
    "np.save(os.path.join(save_dir, 'g_denoise_all_n3.npy'), g_denoised_all, allow_pickle=True)\n",
    "\n",
    "print(f'Arrays saved to {save_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890107d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_denoised_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a53eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recover_rate = p_sim_all[:, :, 0].mean(axis=1)  # 每个pattern在最大噪声强度下的平均恢复率\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(g_idxed, mean_recover_rate, color='skyblue')\n",
    "plt.xlabel('Pattern Index')\n",
    "plt.ylabel('Mean Recovery Rate (Cosine Similarity)')\n",
    "plt.title('Mean Recovery Rate for Each Pattern at Noise STD={}'.format(ls_noise[0]))\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(g_idxed)\n",
    "plt.grid(axis='y', color='grey', linestyle='--', alpha=0.7\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec375260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of all patterns\n",
    "p_noise_all[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化每个 g-p 模式的去噪效果（包含去噪前后 place pattern）\n",
    "denoise_fig_dir = os.path.join(folder_path, '020510', 'gp_denoise_inspection')\n",
    "os.makedirs(denoise_fig_dir, exist_ok=True)\n",
    "grid_axis = np.arange(N)\n",
    "for idx, g_id in enumerate(g_idxed):\n",
    "    grid_org = np.asarray(pattern_average_activity[g_id], dtype=float).reshape(-1)\n",
    "    grid_denoise = np.asarray(g_denoised_all[idx], dtype=float).reshape(-1)\n",
    "    place_clean = np.asarray(p_tests[idx], dtype=float).reshape(-1)\n",
    "    place_noisy = np.asarray(p_noise_all[idx], dtype=float).reshape(-1)\n",
    "    place_denoised = np.asarray(p_denoised_all[idx], dtype=float).reshape(-1)\n",
    "    vmax_place = float(max(np.max(place_clean), np.max(place_noisy), np.max(place_denoised), 1e-6))\n",
    "    grid_min = float(np.min([grid_org.min(), grid_denoise.min()]))\n",
    "    grid_max = float(np.max([grid_org.max(), grid_denoise.max()]))\n",
    "    grid_range = max(grid_max - grid_min, 1e-6)\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    gs = fig.add_gridspec(3, 2, width_ratios=[2, 3], height_ratios=[1, 1, 1], wspace=0.05, hspace=0.15)\n",
    "    ax_line = fig.add_subplot(gs[:, 0])\n",
    "    ax_line.plot(grid_axis, grid_org, color='steelblue', linewidth=2, label='grid_org')\n",
    "    ax_line.plot(grid_axis, grid_denoise, color='darkorange', linestyle='--', linewidth=2, label='grid_denoise')\n",
    "    ax_line.set_xlim(0, N - 1)\n",
    "    ax_line.set_ylim(grid_min - 0.05 * grid_range, grid_max + 0.05 * grid_range)\n",
    "    ax_line.set_xlabel('Grid cell index')\n",
    "    ax_line.set_ylabel('Activity')\n",
    "    ax_line.set_title(f'g-p denoise comparison | g_idx={g_id}')\n",
    "    ax_line.legend(loc='upper right', fontsize='small')\n",
    "    heatmap_data = [\n",
    "        ('p_test (clean)', place_clean),\n",
    "        ('p_noisy', place_noisy),\n",
    "        ('p_denoised', place_denoised),\n",
    "    ]\n",
    "    for row, (title, data) in enumerate(heatmap_data):\n",
    "        ax_heat = fig.add_subplot(gs[row, 1])\n",
    "        heatmap_array = np.asarray(data, dtype=float)[None, :]\n",
    "        ax_heat.imshow(heatmap_array, aspect='auto', cmap='gray', vmin=0.0, vmax=vmax_place, extent=[0, Nh, 0, 1])\n",
    "        ax_heat.set_title(title, fontsize=9, pad=4)\n",
    "        ax_heat.set_yticks([])\n",
    "        if row < len(heatmap_data) - 1:\n",
    "            ax_heat.set_xticks([])\n",
    "        else:\n",
    "            ax_heat.set_xlabel('Place cell index')\n",
    "        for spine in ax_heat.spines.values():\n",
    "            spine.set_visible(False)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.suptitle(f'g_id {g_id} denoising', y=0.995, fontsize=12)\n",
    "    out_path = os.path.join(denoise_fig_dir, f'g_idx_{g_id:04d}_denoise.png')\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1795ece",
   "metadata": {},
   "source": [
    "### 不训练条件下的系统性吸引子检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25766e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_indexes_all = np.arange(pattern_average_activity.shape[0])\n",
    "g_indexes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_idxes = g_indexes_all.tolist()\n",
    "p_tests = []\n",
    "T_s = 5   # 保证收敛\n",
    "dt = 0.0005\n",
    "for g_id in g_idxes:\n",
    "    grid_org = pattern_average_activity[g_id].reshape(-1,1)\n",
    "    s_new = np.vstack([grid_org, grid_org])   # initialize with previous g\n",
    "    # print(s_new.shape)\n",
    "    p_hist = np.zeros((Nh,n_steps_test))\n",
    "    p_test = np.zeros((Nh, )) \n",
    "    n_steps_test = int(T_s/dt)\n",
    "    # p_hist = np.zeros((Nh,n_steps_test))\n",
    "    for t in range(n_steps_test):\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_new = p_test + dt / tau_h * (-p_test + phi_term.flatten())\n",
    "        # r_place_test[:, t:t+1] = p_new.reshape(-1, 1)\n",
    "        p_test = p_new.flatten()\n",
    "        p_hist[:,t] = p_test\n",
    "    # print(p_test.shape)\n",
    "    p_tests.append(p_test)\n",
    "p_tests = np.stack(p_tests)  # (Npatts, Nh)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10,4))\n",
    "# 只打印最后一个pattern的place cell活动随时间变化\n",
    "plt.plot(np.mean(p_hist, axis=0))\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Mean Place Cell Activity')  \n",
    "plt.title('Place Cell Activity Over Time for Archetype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attractor_test2(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max = 2, dt = 0.01, Nrun = 100,noise_stds = [2], sim_measure = 'Cosine'):\n",
    "    '''验证多个噪声强度下网络的去噪能力'''\n",
    "    Nn = len(noise_stds)\n",
    "    n_steps_test = int(T_max / dt)\n",
    "    p_sim_all = np.zeros((Nrun, Nn, n_steps_test))  # collect p similarity over time_steps\n",
    "    for n in range(Nn):\n",
    "        noise_std = noise_stds[n]\n",
    "        for r in range(Nrun):\n",
    "            p_noise, p_denoised, sim_array, g_denoised = g_p_denoise_process(grid_org, p_org, Wgp_L, Wgp_R, W_pg, T_max, dt, noise_std, sim_measure)\n",
    "            p_sim_all[r, n, :] = sim_array\n",
    "    \n",
    "    return p_noise, p_denoised, p_sim_all, g_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f49e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个保存所有时刻的相似度变化曲线\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ls_noise = [2.0]\n",
    "T_max = 1.5\n",
    "dt = 0.0005\n",
    "g_idxed = g_indexes_all\n",
    "\n",
    "grid_global_min = 0.0\n",
    "grid_global_max = pattern_average_activity[g_idxed, :].max()\n",
    "place_global_max = p_tests.max()\n",
    "time_axis = np.arange(int(T_max / dt)) * dt\n",
    "\n",
    "place_pattern_cache = {g_id: p_tests[idx] for idx, g_id in enumerate(g_idxed)}\n",
    "T_s_relax = 5.0\n",
    "dt_relax = dt\n",
    "relax_steps = int(T_s_relax / dt_relax)\n",
    "def compute_place_pattern(g_id):\n",
    "    grid_org = pattern_average_activity[g_id].reshape(-1, 1)\n",
    "    s_new = np.vstack([grid_org, grid_org])\n",
    "    p_state = np.zeros(Nh)\n",
    "    for _ in range(relax_steps):\n",
    "        hippo_drive = gain_pg * W_pg @ s_new + Iext2\n",
    "        phi_term = relu(hippo_drive - theta).reshape(-1, 1)\n",
    "        p_state = p_state + dt_relax / tau_h * (-p_state + phi_term.flatten())\n",
    "    return p_state\n",
    "\n",
    "def get_place_pattern(g_id):\n",
    "    if g_id not in place_pattern_cache:\n",
    "        place_pattern_cache[g_id] = compute_place_pattern(g_id)\n",
    "    return place_pattern_cache[g_id]\n",
    "\n",
    "@contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "    old_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_callback\n",
    "        tqdm_object.close()\n",
    "\n",
    "def _simulate_pattern(task):\n",
    "    _, g_id = task\n",
    "    grid_org = pattern_average_activity[g_id]\n",
    "    p_org = get_place_pattern(g_id)\n",
    "    return attractor_test2(\n",
    "        grid_org,\n",
    "        p_org,\n",
    "        Wgp_L_pre,\n",
    "        Wgp_R_pre,\n",
    "        W_pg,\n",
    "        T_max=T_max,\n",
    "        dt=dt,\n",
    "        Nrun=100,\n",
    "        noise_stds=ls_noise,\n",
    "        sim_measure='Cosine'\n",
    "    )\n",
    "\n",
    "n_jobs = min(len(g_idxed), os.cpu_count() or 1)\n",
    "with tqdm_joblib(tqdm(total=len(g_idxed), desc='Running attractor tests')):\n",
    "    results = Parallel(n_jobs=n_jobs, prefer='threads')(\n",
    "        delayed(_simulate_pattern)(task) for task in enumerate(g_idxed)\n",
    "    )\n",
    "\n",
    "p_noise_all, p_denoised_all, p_sim_all, g_denoised_all = [\n",
    "    list(values) for values in zip(*results)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exoprt results\n",
    "time = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "# export_dir = os.path.join(folder_path, 'exports', f'pg_Mul-1D_denoise_{N}_{time}')\n",
    "# os.makedirs(export_dir, exist_ok=True)\n",
    "export_dir = r'D:\\\\prob_learning\\\\grid_cell\\\\202601_Loop model\\\\visualization\\\\exports\\\\pg_Mul-1D_denoise_32_0206'\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'p_sim_all.npy'),\n",
    "    np.array(p_sim_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(export_dir, 'g_denoised_all.npy'),\n",
    "    np.array(g_denoised_all, dtype=object),\n",
    "    allow_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00571b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim_all_arr = np.array(p_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recover_rate = p_sim_all_arr[:, :, 0, -1].mean(axis=1)  # 每个pattern在最大噪声强度下的平均恢复率\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(g_idxed, mean_recover_rate, color='skyblue') \n",
    "plt.xlabel('Pattern Index')\n",
    "plt.ylabel('Mean Recovery Rate (Cosine Similarity)')\n",
    "plt.title('Mean Recovery Rate for Each Pattern at Noise STD={}'.format(ls_noise[0]))\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(g_idxed)\n",
    "plt.grid(axis='y', color='grey', linestyle='--', alpha=0.7\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac67e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
